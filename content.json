{"posts":[{"title":"GDB学习","text":"1 调试入门及基础篇1-1 Linux C/C++调试准备工作Ubuntu: apt install gcc g++ make gdb 123456789101112#include&lt;iostream&gt;int main(int argc,char**argv){ int itest=100; const char *str=&quot;this is a test&quot;; std::cout &lt;&lt; &quot;itest is &quot; &lt;&lt; itest &lt;&lt; &quot;,str is &quot; &lt;&lt; str &lt;&lt; std::endl; std::cout &lt;&lt; &quot;参数为:&quot; &lt;&lt; std::endl; for (int i = 0; i &lt; argc; i++){ std::cout &lt;&lt; argv[i] &lt;&lt; std::endl; } std::cout &lt;&lt; &quot;Hello world\\n&quot;; return 0;} 生成可调试的代码：g++ -g test.cpp -o test 进行调试：gdb test list：显示源码，一次默认显示10行 break/b：插入断点 info/i：查看信息 run/r：执行程序 next/n：执行一步 print/p：查看变量名 locals：看局部变量 continue/c：继续执行，直到下一个断点 1-2 启动调试1-2-1 启动调试并传入参数 gdb –args &lt;exe&gt; set args &lt;args&gt; r &lt;args&gt; gdb –args &lt;exe&gt; set args &lt;args&gt; r &lt;args&gt; 1-2-2 附加到进程，适用于已经启动的程序 gdb attach &lt;pid&gt; gdb –pid &lt;pid&gt; gdb attach &lt;pid&gt; gdb –pid &lt;pid&gt; 1-2-3 逐过程执行单步执行（step-over），遇到函数跳过函数 next/n 1-2-4 逐语句执行单步执行（step-into），遇到函数进入函数 step/s 1-2-5 退出当前函数finish 1-2-6 退出调试detach（分离） quit/q（退出） 1-3 调试断点管理1-3-1 设置断点 break/b 文件名:行号，在源代码某一行设置断点 b 函数名：为函数设置断点，同名函数会怎么样？（都添加断点） rb 正则表达式：为满足正则表达式的函数设置断点 b 断点条件：设置条件断点 tb 断点：设置临时断点（只命中一次） 1-3-2 查看/禁用/删除断点 i b：查看所有断点 disable/enable 断点编号：禁用，启用断点 delete 断点：删除断点 1-4 变量查看与修改1-4-1 变量查看 info args：查看函数参数 print/p 变量名：查看变量的值 set print null-stop：设置字符串的显示规则 set print pretty：显示结构体 set print array on：显示数组 使用gdb内嵌函数，比如sizeof,strlen,strcmp等 info args &amp;&amp; print/p 变量名 set print null-stop set print pretty set print array on 使用gdb内嵌函数 1-4-2 变量更改 p 变量=修改值：包括普通变量，结构体，类等 1-5 内存查看与修改1-5-1 内存查看 x /选项 内存地址 x /s str x /d x /4d x /16s 结构体变量地址 1-5-2 内存修改 set 地址=修改值 1-6 寄存器查看与修改1-6-1 查看寄存器 i registers i r rdi … 6个参数以内放寄存器，多的放栈 寄存器 函数参数 rdi 第一个参数 rsi 第二个参数 rdx 第三个参数 rcx 第四个参数 r8 第五个参数 r9 第六个参数 1-6-2 修改寄存器pc/rip (problem counter)寄存器，保存程序下一条要执行的指令，通过修改pc寄存器来改变程序执行的流程 set var $pc=xxx p $rip=xxx info line 行数：查看汇编代码地址 1-7 源代码管理、查看、搜索1-7-1 源代码管理 list/l：显示源代码，默认显示10行（l - ：向前显示） set listsize xx：设置每次显示的行数 list test_fun：查看指定函数代码 list main.cpp:15：查看指定文件指定行代码 1-7-2 搜索源代码 search 正则表达式 forward-search 正则表达式 reverse-search 正则表达式 1-7-3 设置源代码搜索目录show directories：查看当前搜索目录 directory path：添加源代码搜索目录 1-8 函数调用栈管理1-8-1 调用栈管理 backtrace/bt：查看栈回溯信息 frame/f n：切换栈帧 info f n(第几号栈帧)：查看栈帧信息 2 调试中级篇2-1 观察点使用观察点是一个特殊的断点，当表达式的值发生变化时它将中断下来。表达式可以是一个变量的值，也可以包含由运算符组合的一个或多个变量的值，例如a + b。有时被称为数据断点(VC里面就称之为数据断点) watch：写观察点，写变量的时候停下来，hardware watchpoint，不影响性能 rwatch：读观察点 awatch：读写观察点 info watch：查看观察点 delete/disable/enable：删除/禁用/启用观察点 表达式例子： 可指定线程：watch 变量名/表达式 thread 线程号 2-2 捕获点使用捕获点是一个特殊的断点，命令语法为：catch event即捕获到event这个事件的时候，程序就会中断下来 catch assert – Catch failed Ada assertions, when raised. catch catch – Catch an exception, when caught. catch exception – Catch Ada exceptions, when raised. catch exec – Catch calls to exec. catch fork – Catch calls to fork. catch handlers – Catch Ada exceptions, when handled. catch load – Catch loads of shared libraries. catch rethrow – Catch an exception, when rethrown. catch signal - Catch signals by their names and/or numbers. catch syscall – Catch system calls by their names, groups and/ornumbers. catch throw – Catch an exception, when thrown. catch unload – Catch unloads of shared libraries. catch vfork – Catch calls to vfork. 2-3 为断点执行命令1234commands 断点号xxxxxxend 不必每次在断点停下来的时候手动查看值 要删除的话直接commands不输入命令： 12commands 断点号end 导出断点信息：save breakpoints 文件名 加载断点信息：source 文件名 2-4 gdb多窗口管理Text User Interface（TUI） layout src：显示源码窗口 layout asm：显示汇编窗口 layout reg：显示寄存器窗口 layout split：切分窗口 focus/fs src/arm/reg：切换窗口焦点 info win：查看当前拥有焦点的窗口 ctrl+x+a：退出窗口模式 2-5 查看对象类型查看结构体，类，派生类等 whatis ptype /r /o /m /t i variables set print object on 2-6 多线程调试管理 info threads：查看所有线程信息 thread find 地址/LWP/线程名（正则表达式)：查找线程 thread num：切换线程 thread name：设置当前线程名字 b 断点地址 thread id：为线程设置断点 thread apply (多个)线程号 gdb命令：为线程执行命令（避免了切换线程） set print thread-events on|off：设置是否打印线程日志 2-7 执行外部命令以及保存命令及输出 shell/!：执行shell命令 pipe/| gdb命令 | grep 条件：对gdb输出进行筛选 set logging on/off：启用/禁用结果输出 set logging file filename：设置输出文件 set logging overwrite：覆盖输出文件，默认为追加 3 调试高级篇3-1 跳转执行-任意执行代码 jump/j location：即在指定位置恢复执行，如果存在断点，执行到指定位置时将中断下来。如果没有断点，则不会停下来，因此，我们通常会在指定位置设置一个断点。跳转命令不会更改当前堆栈帧、堆栈指针、程序计数器以外的任何寄存器。 3-2 反向执行-调试中的undo record：进行记录 reverse-next：反向运行到上一次被执行的源代码行，但是不进入函数 reverse-finish：反向运行程序回到调用当前函数的地方 record-stop：结束记录 不能用于IO操作 3-3 调试子进程 set follow-fork-mode child/parent：选择调试父进程还是子进程，默认父进程 set detach-on-fork off/on i inferiors：查看进程信息 inferiors n：切换进程 follow-fork-mode detach-on-fork 说明 parent on 只调试主进程( GDB 默认) child on 只调试子进程 parent off 同时调试两个进程, gdb 跟主进程, 子进程 block 在 fork 位置 child off 同时调试两个进程, gdb 跟子进程, 主进程 block 在 fork 位置 3-4 多进程调试先要将进程都attach进来 attach pid set schedule-multiple on detach inferior n 3-5 调试时调用内部、外部函数p表达式：求表达式的值并显示结果值。表达式可以包括对正在调试的程序中的函数的调用，即使函数返回值是void，也会显示。 call 表达式：求表达式的值并显示结果值，如果是函数调用，返回值是void的话，不显示void返回值。 3-6 调试时跳过指定函数指用step不会进入函数 skip 函数名 skip file 文件名：文件中的函数都会被跳过 skip -gfi 通配符：跳过满足通配符的文件 3-7 制作、调试发行版 去掉 -g 参数进行make（自己需要保留有调试信息的版本，所以要make两次） make Debug版本，然后使用 strip -g release-section -o release 命令去掉调试信息（只要make一次） gdb –symbol=release-section -exec=release objcopy –only-keep-debug release-section debug.sym：生成只有调试信息的文件，然后 gdb –symbol=debug.sym -exec=release gdb调试release版core dump文件：gdb release-section rel.core 3-8 软件补丁制作-直接编辑二进制程序 gdb –write 可执行文件：修改可执行文件 disassemble查看反汇编代码，例：disassemble /mr check_some p或者set修改机器码，例：set {unsigned char}0x00000000000011b4=101 4 调试实战篇4-1 内存泄漏检测 call malloc_stats() call malloc_info(0,stdout) 4-2 gcc检测各种内存问题检查：泄漏，栈溢出，野指针等gcc选项 -fsanitize=address检查内存泄漏检查堆溢出检查栈溢出检查全局内存溢出检查释放后再使用 4-3 远程调试1.服务器端/被调试机：安装 gdb server：apt install gdbserver 启动 gdbserver 2.客户端/调试机gdb远程连接并进行调试 4-4 多线程死锁调试分析死锁最常用的命令：thread、bt、f、p等 死锁的条件： 互斥条件 保持和请求条件 不可剥夺条件 循环等待条件 解决死锁的方式： 顺序使用锁 控制锁的作用范围 可以使用超时机制 4-5 核心转储（core dump）基础​ Linux core dump：一般称之为核心转储、内核转储，我们统称为转储文件是某个时刻某个进程的内存信息映射，即包含了生成转储文件时该进程的整个内存信息以及寄存器等信息。转储文件可以是某个进程的，也可以是整个系统的。可以是进程活着的时候生成的，也可以是进程或者系统崩溃的时候自动生成的。​ 为活着的进程创建core dump文件一般可以通过gdb来生成，使用gdb把进程attach进来以后，执行generate-core-file或者gcore命今来生成core dump文件。​ 我们更多时候是对崩溃产生的core dump文件进行分析。 ​ 崩溃时自动生成core文件，需要将 ulimit -c 设置为 unlimted，文件名由/proc/sys/kernel/core_pattern决定 ​ 查看问题：gdb 可执行文件 core文件 4-6 无调试符号core dump分析不能用p打印变量，但可以查看寄存器，查看内存地址的值 参考：SimpleSoft-2020/gdbdebug: gdb debug example (github.com)","link":"/2023/04/03/GDB%E5%AD%A6%E4%B9%A0/"},{"title":"MySQL事务基础与实现原理","text":"1 事务的基本概念事务一般指的是逻辑上的一组操作，或者作为单个逻辑单元执行的一系列操作。同属于一个事务的操作会作为一个整体提交给系统，这些操作要么全部执行成功，要么全部执行失败。 总体来说，事务存在四大特性（ACID），分别是原子性（Atomic）、一致性（Consistency）、隔离性 （Isolation）和持久性（Durability）。 原子性：构成事务的所有操作要么全部执行成功，要么全部执行失败，不可能出现部分执行成功，部分执行失败的情况。 一致性：在事务执行之前和执行之后，数据始终处于一致的状态。 隔离性：并发执行的两个事务之间互不干扰。MySQL 通过锁和 MVCC 机制来保证事务的隔离性。 持久性：是事务提交完成后，此事务对数据的更改操作会被持久化到数据库中，并且不会被回滚。 2 MySQL事务基础2.1 并发事务带来的问题 2.1.1 更新丢失（脏写）当两个或两个以上的事务选择数据库中的同一行数据，并基于最初选定的值更新该行数据时，因为每个事务之间都无法感知彼此的存在，所以会出现最后的更新操作覆盖之前由其他事务完成的更新操作的情况。也就是说，对于同一行数据，一个事务对该行数据的更新操作覆盖了其他事务对该行数据的更新操作。 例如，张三的账户余额是100元，当前有事务A和事务B两个事务，事务A是将张三的账户余额 增加100元，事务B是将张三的账户余额增加200元。起初，事务A和事务B同时读取到张三的账 户余额为100元。然后，事务A和事务B将分别更新张三的银行账户余额，假设事务A先于事务B提交，但事务A和事务B都提交后的结果是张三的账户余额是300元。也就是说，后提交的事务B覆盖了事务A的更新操作。 更新丢失（脏写）本质上是写操作的冲突，解决办法是让每个事务按照串行的方式执行，按照一定的顺序依次进行写操作。 2.1.2 脏读一个事务正在对数据库中的一条记录进行修改操作，在这个事务完成并提交之前，当有另一个事务来读取正在修改的这条数据记录时，如果没有对这两个事务进行控制，则第二个事务就会读取到没有被提交的脏数据，并根据这些脏数据做进一步的处理，此时就会产生未提交的数据依赖关系。我们通常把这种现象称为脏读，也就是一个事务读取了另一个事务未提交的数据。 例如，当前有事务A和事务B两个事务，事务A是向张三的银行账户转账100元，事务B是查询张三的账户余额。事务A执行转账操作，在事务A未提交时，事务B查询到张三的银行账户多了100元，后来事务A由于某些原因，例如服务超时、系统异常等因素进行回滚操作，但事务B查询到的数据并没有改变。此时，事务B查询到的数据就是脏数据。 脏读本质上是读写操作的冲突，解决办法是先写后读，也就是写完之后再读。 2.1.3 不可重复读一个事务读取了某些数据，在一段时间后，这个事务再次读取之前读过的数据，此时发现读取的数据发生了变化，或者其中的某些记录已经被删除，这种现象就叫作不可重复读。即同一个事务，使用相同的查询语句，在不同时刻读取到的结果不一致。 例如，当前有事务A和事务B两个事务，事务A是向张三的银行账户转账100元，事务B是查询张三的账户余额。第一次查询时，事务A还没有转账，第二次查询时，事务A已经转账成功，此 时，就会导致事务B两次查询结果不一致。 不可重复读本质上也是读写操作的冲突，解决办法是先读后写，也就是读完之后再写。 2.1.4 幻读一个事务按照相同的查询条件重新读取之前读过的数据，此时发现其他事务插入了满足当前事务查询条件的新数据，这种现象叫作幻读。即一个事务两次读取一个范围的数据记录，两次读取到的结果不同。 例如，当前有事务A和事务B两个事务，事务A是两次查询张三的转账记录，事务B是向张三的银行账户转账100元。事务A第一次查询时，事务B还没有转账，事务A第二次查询时，事务B已 经转账成功，此时，就会导致事务A两次查询的转账数据不一致。 幻读本质上是读写操作的冲突，解决办法是先读后写，也就是读完之后再写。 2.1.5 不可重复读与幻读的区别 不可重复读的重点在于更新和删除操作，而幻读的重点在于插入操作 幻读无法通过行级锁来避免，需要使用串行化的事务隔离级别，但是这种事务隔离级别会极大降低数据库的并发能力。 从本质上讲，不可重复读和幻读最大的区别在于如何通过锁机制解决问题。 另外，除了可以使用悲观锁来避免不可重复读和幻读的问题外，我们也可以使用乐观锁来处理，例如，MySQL、Oracle和PostgreSQL等数据库为了提高整体性能，就使用了基于乐观锁的MVCC（多版本并发控制）机制来避免不可重复读和幻读。 2.2 MySQL事务隔离级别MySQL中的InnoDB储存引擎提供 SQL标准所描述的4种事务隔离级别，分别为读未提交（Read Uncommitted）、读已提交 （Read Committed）、可重复读（Repeatable Read）和串行化（Serializable）。MySQL中的InnoDB默认为可重复读。Oracle默认为读已提交。 事务隔离级别 脏读 不可重复读 幻读 读未提交 可能 可能 可能 读已提交 不可能 可能 可能 可重复读 不可能 不可能 可能 串行化 不可能 不可能 不可能 2.3 MySQL中锁的分类 Some Tips 实现乐观锁的一种常用做法是为数据增加一个版本标识，如果是通过数据库实现，往往会在数据表中增加一个类似version的版本号字段。在查询数据表中的数据时，会将版本号字段的值一起读取出来，当更新数据时，会令版本号字段的值加1。将提交数据的版本与数据表对应记录的版本进行对比，如果提交的数据版本号大于数据表中当前要修改的数据的版本号，则对数据进行修改操作。否则，不修改数据表中的数据。 表锁开销比较小， 加锁速度快，一般不会出现死锁，锁定的粒度比较大，发生锁冲突的概率最高，并发度最低。行锁开销比较大，加锁速度慢，可能会出现死锁，锁定的粒度最小，发生锁冲突的概率最小，并发度最高。页面锁对数据的加锁开销介于表锁和行锁之间，可能会出现死锁，锁定的粒度大小介于表锁和行锁之间，并发度一般。 行锁主要加在索引上，如果对非索引的字段设置条件进行更新，行锁可能会变成表锁。 InnoDB的行锁是针对索引加锁，不是针对记录加锁，并且加锁的索引不能失效，否则行锁可能会变成表锁。 间隙锁只有在可重复读事务隔离级别下才会生效 2.4 MySQL中如何避免死锁 尽量让数据表中的数据检索都通过索引来完成，避免无效索引导致行锁升级为表锁。 合理设计索引，尽量缩小锁的范围。 尽量减少查询条件的范围，尽量避免间隙锁或缩小间隙锁的范围。 尽量控制事务的大小，减少一次事务锁定的资源数量，缩短锁定资源的时间。 如果一条SQL语句涉及事务加锁操作，则尽量将其放在整个事务的最后执行。 尽可能使用低级别的事务隔离机制。 3 MySQL事务实现原理从某种程度上说，事务的隔离性是由锁和 MVCC 机制实现的，原⼦性和持久性是由Redo Log实现的，一致性是由Undo Log实现的。 3.1 Redo LogRedo Log 确保MySQL事务提交后，事务所涉及的所有操作要么全部执行成功，要么全部执行失败。 3.1.1 Redo Log 基本原理Redo Log也被称作重做日志，它是在InnoDB存储引擎中产生的，用来保证事务的原⼦性和持 久性。Redo Log主要记录的是物理日志，也就是对磁盘上的数据进行的修改操作。Redo Log 往往用来恢复提交后的物理数据页，不过只能恢复到最后一次提交的位置。 Redo Log通常包含两部分：一部分是内存中的日志缓冲，称作Redo Log Buffer，这部分日志比较容易丢失；另一份是存放在磁盘上的重做日志文件，称作Redo Log File，这部分日志是持久化到磁盘上的，不容易丢失。 3.1.2 Redo Log 刷盘规则 在InnoDB存储引擎中，Redo Log具有以下几种刷盘规则。 开启事务，发出提交事务指令后是否刷新日志由变量innodb_flush_log_at_trx_commit决定 每秒刷新一次，刷新日志的频率由变量innodb_flush_log_at_timeout的值决定，默认是1s。 需要注意的是，刷新日志的频率和是否行了commit操作无关 当Log Buffer中已经使用的内存超过一半时，也会触发刷盘操作 对于第一条规则，在进行一定的说明。当事务提交时，需要先将事务日志写入Log Buffer，这些写入Log Buffer的日志并不是随着事务 的提交立刻写入磁盘的，而是根据一定的规则将Log Buffer中的数据刷写到磁盘，从而保证了 Redo Log文件中数据的持久性。这种刷盘规则可以通过innodb_flush_log_at_trx_commit变量 控制，innodb_flush_log_at_trx_commit变量可取的值有0、1和2，默认为1。 如果该变量设置为0，则每次提交事务时，不会将Log Buffer中的日志写入OS Buffer，而是通 过一个单独的线程，每秒写入OS Buffer并调用fsync()函数写入磁盘的Redo Log文件。这种方式不是实时写磁盘的，而是每隔1s写一次日志，如果系统崩溃，可能会丢失1s的数据 如果该变量设置为1，则每次提交事务都会将Log Buffer中的日志写入OS Buffer，并且会调用 fsync()函数将日志数据写入磁盘的Redo Log文件中。这种方式虽然在系统崩溃时不会丢失数 据，但是性能比较差。如果没有设置innodb_flush_log_at_trx_commit变量的值，则默认为1 如果该变量设置为2，则每次提交事务时，都只是将数据写入OS Buffer，之后每隔1s，通过 fsync()函数将OS Buffer中的日志数据同步写入磁盘的Redo Log文件中。 3.2 Undo LogUndo Log在MySQL事务的实现中主要起到两方面的作用：回滚事务和多版本并发事务，也就是常说的MVCC机制。在MySQL启动事务之前，会先将要修改的数据记录存储到Undo Log中。如果数据库的事务回滚或者MySQL数据库崩溃，可以利用Undo Log对数据库中未提交的事务进行回滚操作，从而保证数据库中数据的一致性。 Undo Log会在事务开始前产生，当事务提交时，并不会立刻删除相应的Undo Log。此时，InnoDB存储引擎会将当前事务对应的Undo Log放入待删除的列表，接下来，通过一个后台线程purge thread进行删除处理。 Undo Log与Redo Log不同，Undo Log记录的是逻辑日志，可以这样理解：当数据库执行一条 insert语句时，Undo Log会记录一条对应的delete语句；当数据库执行一条delete语句时，Undo Log会记录一条对应的insert语句；当数据库执行一条update语句时，Undo Log会记 录一条相反的update语句。 需要注意的是，因为MySQL事务执行过程中产生的Undo Log也需要进行持久化操作，所以 Undo Log也会产生Redo Log。由于Undo Log的完整性和可靠性需要Redo Log来保证，因此数据库崩溃时需要先做Redo Log数据恢复，然后做Undo Log回滚。 3.3 BinLogRedo Log是InnoDB存储引擎特有的日志，MySQL也有其自身的日志，这个日志就是BinLog， 即二进制日志。 3.3.1 BinLog基本概念BinLog是一种记录所有MySQL数据库表结构变更以及表数据变更的二进制日志。BinLog中不会记录诸如select和show这类查询操作的日志，同时，BinLog是以事件形式记录相关变更操作 的，并且包含语句执行所消耗的时间。BinLog有以下两个最重要的使用场景： 主从复制：在主数据库上开启BinLog，主数据库把BinLog发送至从数据库，从数据库获取BinLog后通过I/O线程将日志写到中继日志，也就是Relay Log中。然后，通过SQL线程将 Relay Log中的数据同步至从数据库，从而达到主从数据库数据的一致性。 数据恢复：当MySQL数据库发生故障或者崩溃时，可以通过BinLog进行数据恢复。例如， 可以使用mysqlbinlog等工具进行数据恢复。 3.3.2 BinLog记录模式BinLog文件中主要有3种记录模式，分别为Row、Statement和Mixed Row模式 Row模式下的BinLog文件会记录每一行数据被修改的情况，然后在MySQL从数据库中对相同的数据进行修改。 Row模式的优点是能够非常清楚地记录每一行数据的修改情况，完全实现主从数据库的同步和数据的恢复。 Row模式的缺点是如果主数据库中发生批量操作，尤其是大批量的操作，会产生大量的二进制日志。比如，使用alter table操作修改拥有大量数据的数据表结构时，会使二进制日志的内容暴涨，产生大量的二进制日志，从而大大影响主从数据库的同步性能。 Statement模式 Statement模式下的BinLog文件会记录每一条修改数据的SQL语句，MySQL从数据库在复制 SQL语句的时候，会通过SQL进程将BinLog中的SQL语句解析成和MySQL主数据库上执行过的 SQL语句相同的SQL语句，然后在从数据库上执行SQL进程解析出来的SQL语句。 Statement模式的优点是由于不记录数据的修改细节，只是记录数据表结构和数据变更的SQL 语句，因此产生的二进制日志数据量比较小，这样能够减少磁盘的I/O操作，提升数据存储和恢复的效率。 Statement模式的缺点是在某些情况下，可能会导致主从数据库中的数据不一致。例如，在 MySQL主数据库中使用了last_insert_id()和now()等函数，会导致MySQL主从数据库中的数据不一致。 Mixed模式 Mixed模式下的BinLog是Row模式和Statement模式的混用。在这种模式下，一般会使用 Statement模式保存BinLog，如果存在Statement模式⽆法复制的操作，例如在MySQL主数据库中使用了last_insert_id()和now()等函数，MySQL会使用Row模式保存BinLog。也就是说， 如果将BinLog的记录模式设置为Mixed,MySQL会根据执行的SQL语句选择写入的记录模式。 3.3.3 BinLog和Redo Log的区别 BinLog是MySQL本身就拥有的，不管使用何种存储引擎，BinLog都存在，而Redo Log是 InnoDB存储引擎特有的，只有InnoDB存储引擎才会输出Redo Log。 BinLog是一种逻辑日志，记录的是对数据库的所有修改操作，而Redo Log是一种物理日志，记录的是每个数据页的修改。 Redo Log具有幂等性，多次操作的前后状态是一致的，而BinLog不具有幂等性，记录的是所有影响数据库的操作。例如插入一条数据后再将其删除，则Redo Log前后的状态未发生变化，而BinLog就会记录插入操作和删除操作。 BinLog开启事务时，会将每次提交的事务一次性写入内存缓冲区，如果未开启事务，则每次成功执行插入、更新和删除语句时，就会将对应的事务信息写入内存缓冲区，而Redo Log是 在数据准备修改之前将数据写入缓冲区的Redo Log中，然后在缓冲区中修改数据。而且在提交事务时，先将Redo Log写入缓冲区，写入完成后再提交事务。 BinLog只会在事务提交时，一次性写入BinLog，其日志的记录方式与事务的提交顺序有 关，并且一个事务的BinLog中间不会插入其他事务的BinLog。而Redo Log记录的是物理页的修改，最后一个提交的事务记录会覆盖之前所有未提交的事务记录，并且一个事务的Redo Log 中间会插入其他事务的Redo Log。 BinLog是追加写入，写完一个日志文件再写下一个日志文件，不会覆盖使用，而Redo Log 是循环写入，日志空间的大小是固定的，会覆盖使用。 BinLog一般用于主从复制和数据恢复，并且不具备崩溃自动恢复的能力，而Redo Log是在服务器发生故障后重启MySQL，用于恢复事务已提交但未写入数据表的数据。 参考：深入理解分布式事务：原理与实战","link":"/2023/04/05/MySQL%E4%BA%8B%E5%8A%A1%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2023/04/03/hello-world/"},{"title":"使用chatgpt练习gdb","text":"奇怪的想法chatgpt有着出色的代码生成能力，于是想利用chatgpt生成含bug代码，训练一下gdb水平。 Test 1 先运行代码，输出的结果是 其实肉眼已经看出来是数组越界访问了，没关系，我们当作不知道，用gdb来debug 先在find_max_index打一个断点，看一看传进去的变量，可以看到arr数组正确，长度为5正确 然后在循环出打个条件断点，在 i == 5 的时候停下，为什么是5？因为开天眼了。在实践中发现在for语句打变量条件断点会失败？？？只能打在for循环中的第一句。然后我们查看一下变量值，发现问题 关于for语句打变量条件断点会失败：尝试后发现，在for语句打断点，只会在第一次进入for时停止，之后便不再触发。 Test 2 拿到代码先运行，愉快死锁 查看进程的pid，pid为8970，attach进行调试 之后我们先看一看线程信息 可以看到有三个线程，一个主线程，两个子线程，Thread2 正在等待 mutex2，Thread3 正在等待 mutex1，然后打印 mutex1和mutex2 可以看到 mutex1 的拥有者是线程8971，就是Thread2，mutex2 的拥有者是线程8972，就是 Thread3，所以死锁。","link":"/2023/04/12/%E4%BD%BF%E7%94%A8chatgpt%E7%BB%83%E4%B9%A0gdb/"},{"title":"常用设计模式","text":"1 设计模式的六大原则 SRP（Single Responsibility Principle）：单一职责原则，一个类只负责一个功能领域中的相应职责，或者可以定义为：就一个类而言，应该只有一个引起它变化的原因。 OCP（Open Close Principle）：开放封闭原则，软件实体可以扩展，但是不可修改。即面对需求，对程序的改动可以通过增加代码来完成，但是不能改动现有的代码。 LSP（Liskov Substitution Principle）：里氏代换原则，就是基类出现的地方，通过它的子类也完全可以实现这个功能。 DIP（Dependence Inversion Principle）：依赖倒置原则，高层模块不应该依赖低层模块，两者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象，其核心思想是：要面向接口编程，不要面向实现编程。 ISP（Interface Segregation Principle）：接口隔离原则，建立一接口，尽量细化接口，接口中的方法尽量少。每个接口中不存在派生类用不到却必须实现的方法，如果不然，就要将接口拆分，使用多个隔离的接口。 CRP（Composite Reuse Principle）：迪米特原则，如果两个类不直接通信，那么这两个类就不应当发生直接的相互作用。如果一个类需要调用另一个类 的某个方法的话，可以通过第三个类转发这个调用。 2 三类设计模式 创造型模式：单例模式、工厂模式、建造者模式、原型模式 结构型模式：适配器模式、桥接模式、外观模式、组合模式、装饰模式、享元模式、代理模式 行为型模式：责任链模式、命令模式、解释器模式、迭代器模式、中介者模式、备忘录模式、观察者模式、状态模式、策略模式、模板方法模式、访问者模式 3 常见设计模式3.1 单例模式保证一个类仅有一个实例，并提供一个访问它的全局访问点。 有两种，懒汉和饿汉： 饿汉：饿了就饥不择食了，所以在单例类定义的时候就进行实例化。 懒汉：顾名思义，不到万不得已就不会去实例化类，也就是在第一次用到的类实例的时候才会去实例化。 饿汉模式（线程安全） 123456789101112131415161718192021222324#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;class SingleInstance{ public: static SingleInstance* GetInstance(){ static SingleInstance ins; return &amp;ins; } ~SingleInstance(){}; private: // 涉及到创建对象的函数都设置为private SingleInstance() { std::cout&lt;&lt;&quot;SingleInstance() 饿汉&quot;&lt;&lt;std::endl; } SingleInstance(const SingleInstance&amp; other) {}; SingleInstance&amp; operator=(const SingleInstance&amp; other) {return *this;}};int main(){ //因为不能创建对象所以通过静态成员函数的⽅法返回静态成员变量 SingleInstance* ins = SingleInstance::GetInstance(); return 0;}//输出 SingleInstance() 饿汉 懒汉模式（线程安全需要加锁） 尽可能的晚的创建这个对象的实例，即在单例类第一次被引用的时候就将自己初始化，C++ 很多地方都有类型的思想，比如写时拷贝，晚绑定等。 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;thread&gt;#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;class SingleInstance{ public: static SingleInstance* GetInstance(){ if (ins == nullptr){ lock_guard&lt;mutex&gt; lck(mLock); if (ins == nullptr){ ins = new SingleInstance(); } } return ins; } ~SingleInstance(){}; private: //涉及到创建对象的函数都设置为private SingleInstance() { std::cout&lt;&lt;&quot;SingleInstance() 懒汉&quot;&lt;&lt;std::endl; } SingleInstance(const SingleInstance&amp; other) {}; SingleInstance&amp; operator=(const SingleInstance&amp; other) { return *this; } static mutex mLock; static SingleInstance* ins;};//懒汉式 静态变量需要定义SingleInstance* SingleInstance::ins = nullptr;mutex SingleInstance::mLock;int main(){ //因为不能创建对象所以通过静态成员函数的⽅法返回静态成员变ᰁ SingleInstance* ins = SingleInstance::GetInstance(); delete ins; return 0;}//输出 SingleInstance() 懒汉 3.2 工厂模式简单工厂模式： 就是建立一个工厂类，对实现了同一接口的一些类进行实例的创建。简单工厂模式的实质是由一个工厂类根据传入的参数，动态决定应该创建哪一个产品类（这些产品类继承自一个父类或接口）的实例。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;using namespace std;// 产品类（抽象类，不能实例化）class Product{ public: Product(){}; virtual void show()=0; //纯虚函数};class productA : public Product{ public: productA(){}; void show(){ std::cout &lt;&lt; &quot;product A create!&quot; &lt;&lt; std::endl; }; ~productA(){};};class productB : public Product{ public: productB(){}; void show(){ std::cout &lt;&lt; &quot;product B create!&quot; &lt;&lt; std::endl; }; ~productB(){};};// 工厂类class simpleFactory{ public: simpleFactory(){}; Product* product(const string str){ if (str == &quot;productA&quot;) return new productA(); if (str == &quot;productB&quot;) return new productB(); return NULL; };};int main(){ simpleFactory obj; // 创建工厂 Product* pro; // 创建产品 pro = obj.product(&quot;productA&quot;); pro-&gt;show(); // product A create! delete pro; pro = obj.product(&quot;productB&quot;); pro-&gt;show(); // product B create! delete pro; return 0;} 工厂模式目的就是代码解耦，如果我们不采用工厂模式，如果要创建产品 A、B，通常做法采用switch…case语 句，那么想后期添加更多的产品进来，我们不是要添加更多的 switch…case 吗？这样就很麻烦，而且也不符合设计模式中的开放封闭原则。 为了进一步解耦，在简单工厂的基础上发展出了抽象工厂模式，即连工厂都抽象出来，实现了进一步代码解耦。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;iostream&gt;#include &lt;thread&gt;using namespace std;// 产品类（抽象类，不能实例化）class Product{ public: Product(){}; virtual void show()=0; //纯虚函数};//抽象类class Factory{ public: virtual Product* CreateProduct()=0;//纯虚函数};class productA : public Product{ public: productA(){}; void show(){ std::cout &lt;&lt; &quot;product A create!&quot; &lt;&lt; std::endl; }; ~productA(){};};class productB : public Product{ public: productB(){}; void show(){ std::cout &lt;&lt; &quot;product B create!&quot; &lt;&lt; std::endl; }; ~productB(){};};//⼯⼚类A，只⽣产A产品class FactorA: public Factory{ public: Product* CreateProduct(){ Product* product_ = new ProductA(); return product_; }};//⼯⼚类B，只⽣产B产品class FactorB: public Factory{ public: Product* CreateProduct(){ Product* product_ = new ProductB(); return product_; }};int main(){ Product* product_ = nullptr; auto MyFactoryA = new FactorA(); product_ = MyFactoryA-&gt;CreateProduct();// 调用产品A的⼯⼚来⽣产A产品 product_-&gt;show(); delete product_; auto MyFactoryB=new FactorB(); product_ = MyFactoryB-&gt;CreateProduct();// 调用产品B的⼯⼚来⽣产B产品 product_-&gt;show(); delete product_; return 0;}//输出//product A create! product B create! 3.3 观察者模式定义一种一（被观察类）对多（观察类）的关系，让多个观察对象同时监听一个被观察对象，被观察对象状态发生变化时，会通知所有的观察对象，使他们能够更新自己的状态。 观察者模式中存在两种角色： 观察者：内部包含被观察者对象，当被观察者对象的状态发生变化时，更新自己的状态（接收通知更新状态） 被观察者：内部包含了所有观察者对象，当状态发生变化时通知所有的观察者更新自己的状态（发送通知） 应用场景：当一个对象的改变需要同时改变其他对象，且不知道具体有多少对象有待改变时，应该考虑使用观察者模式；一个抽象模型有两个方面，其中一方面依赖于另一方面，这时可以用观察者模式将这两者封装在独立的对象中使它们各自独立地改变和复用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;list&gt;using namespace std;class Subject;//观察者 基类 （内部实例化了被观察者的对象sub）class Observer { protected: string name; Subject *sub; public: Observer(string name, Subject *sub) { this-&gt;name = name; this-&gt;sub = sub; } virtual void update() = 0;};class StockObserver : public Observer { public: StockObserver(string name, Subject *sub) : Observer(name, sub){} void update();};class NBAObserver : public Observer { public: NBAObserver(string name, Subject *sub) : Observer(name, sub){} void update();};//被观察者基类 （内部存放了所有的观察者对象，以便状态发⽣变化时，给观察者发通知）class Subject { protected: std::list&lt;Observer *&gt; observers; public: string action; //被观察者对象的状态 virtual void attach(Observer *) = 0; virtual void detach(Observer *) = 0; virtual void notify() = 0;};class Secretary : public Subject { void attach(Observer *observer) { observers.push_back(observer); } void detach(Observer *observer) { list&lt;Observer *&gt;::iterator iter = observers.begin(); while (iter != observers.end()) { if ((*iter) == observer) { observers.erase(iter); return; } ++iter; } } void notify() { list&lt;Observer *&gt;::iterator iter = observers.begin(); while (iter != observers.end()) { (*iter)-&gt;update(); ++iter; } }};void StockObserver::update() { cout &lt;&lt; name &lt;&lt; &quot; 收到消息：&quot; &lt;&lt; sub-&gt;action &lt;&lt; endl; if (sub-&gt;action == &quot;⽼板来了!&quot;) { cout &lt;&lt; &quot;我⻢上关闭股票，装做很认真⼯作的样⼦！&quot; &lt;&lt; endl; }}void NBAObserver::update() { cout &lt;&lt; name &lt;&lt; &quot; 收到消息：&quot; &lt;&lt; sub-&gt;action &lt;&lt; endl; if (sub-&gt;action == &quot;⽼板来了!&quot;) { cout &lt;&lt; &quot;我⻢上关闭 NBA，装做很认真⼯作的样⼦！&quot; &lt;&lt; endl; }}int main(){ Subject *BOSS = new Secretary(); Observer *xa = new NBAObserver(&quot;xa&quot;, BOSS); Observer *xb = new NBAObserver(&quot;xb&quot;, BOSS); Observer *xc = new StockObserver(&quot;xc&quot;, BOSS); BOSS-&gt;attach(xa); BOSS-&gt;attach(xb); BOSS-&gt;attach(xc); BOSS-&gt;action = &quot;去吃饭了！&quot;; BOSS-&gt;notify(); cout &lt;&lt; endl; BOSS-&gt;action = &quot;⽼板来了!&quot;; BOSS-&gt;notify(); return 0;} 3.4 装饰器模式装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。 这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。 代码没有改变 Car 类的内部结构，还为其增加了新的功能，这就是装饰器模式的作用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;iostream&gt;#include &lt;list&gt;#include &lt;memory&gt;using namespace std;//抽象构件类 Transform (变形⾦刚)class Transform{ public: virtual void move() = 0;};//具体构件类Carclass Car : public Transform{ public: Car(){ std::cout &lt;&lt; &quot;变形⾦刚是⼀辆⻋！&quot; &lt;&lt; endl; } void move(){ std::cout &lt;&lt; &quot;在陆地上移动。&quot; &lt;&lt; endl; }};//抽象装饰类class Changer : public Transform{ public: Changer(shared_ptr&lt;Transform&gt; transform){ this-&gt;transform = transform; } void move(){ transform-&gt;move(); } private: shared_ptr&lt;Transform&gt; transform;};//具体装饰类Robotclass Robot : public Changer{ public: Robot(shared_ptr&lt;Transform&gt; transform) : Changer(transform){ std::cout &lt;&lt; &quot;变成机器⼈!&quot; &lt;&lt; std::endl; } void say(){ std::cout &lt;&lt; &quot;说话!&quot; &lt;&lt; std::endl; }};//具体装饰类AirPlaneclass Airplane : public Changer{ public: Airplane(shared_ptr&lt;Transform&gt; transform) : Changer(transform){ std::cout &lt;&lt; &quot;变成⻜机!&quot; &lt;&lt; std::endl; } void say(){ std::cout &lt;&lt; &quot;在天空⻜翔!&quot; &lt;&lt; std::endl; } };int main(void){ shared_ptr&lt;Transform&gt; camaro = make_shared&lt;Car&gt;(); camaro-&gt;move(); std::cout &lt;&lt; &quot;--------------&quot; &lt;&lt; endl; shared_ptr&lt;Robot&gt; bumblebee = make_shared&lt;Robot&gt;(camaro); bumblebee-&gt;move(); bumblebee-&gt;say(); return 0;}/*输出变形⾦刚是⼀辆⻋！在陆地上移动。--------------变成机器⼈!在陆地上移动。说话!*/ 参考： 常见C++设计模式面试题和场景题_牛客网 (nowcoder.com) 20 万字的 C++ 八股文&amp;图解源码，发布！ (qq.com)","link":"/2023/04/10/%E5%B8%B8%E7%94%A8%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"title":"常见排序算法","text":"1 常见排序算法及其时间和空间复杂度 排序算法 平均时间复杂度 最好情况 最坏情况 空间复杂度 稳定性 冒泡排序 $O(n^2)$ $O(n)$ $O(n^2)$ $O(1)$ 稳定 选择排序 $O(n^2)$ $O(n^2)$ $O(n^2)$ $O(1)$ 不稳定 插入排序 $O(n^2)$ $O(n)$ $O(n^2)$ $O(1)$ 稳定 希尔排序 $O(n^\\frac{3}{2})$ $O(nlog2n)$ $O(n^2)$ $O(1)$ 不稳定 归并排序 $O(nlogn)$ $O(nlogn)$ $O(nlogn)$ $O(n)$ 稳定 快速排序 $O(nlogn)$ $O(nlogn)$ $O(n^2)$ $O(logn)$ 不稳定 堆排序 $O(nlogn)$ $O(nlogn)$ $O(nlogn)$ $O(1)$ 不稳定 计数排序 $O(n+k)$ $O(n+k)$ $O(n+k)$ $O(k)$ 稳定 桶排序 $O(n+k)$ $O(n+k)$ $O(n^2)$ $O(n+k)$ 稳定 基数排序 $O(n\\times k)$ $O(n\\times k)$ $O(n\\times k)$ $O(n+k)$ 稳定 2 冒泡排序算法描述：比较相邻的元素。如果第一个比第二个大，就交换它们两个。 12345678910111213141516void BubbleSort(vector&lt;int&gt; &amp;nums){ int n = nums.size(); // 第i轮确定第i大的值，只需判断n-1轮 for (int i = 0; i &lt; n-1; ++i){ // 判断当前轮有无变化，没有变化说明已经排序完成 bool flag = false; // 后i+1位已经在之前轮排序完成 for (int j = 0; j &lt; n-1-i; ++j){ if (nums[j] &gt; nums[j+1]){ swap(nums[j], nums[j+1]); flag = true; } } if (!flag) break; }} 3 选择排序算法描述：分已排序区间和未排序区间。每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾。 123456789101112void SelectSort(vector&lt;int&gt; &amp;nums){ int n = nums.size(); for (int i = 0; i &lt; n-1; ++i){ int pos = i; for (int j = i+1; j &lt; n; ++j){ if (nums[j] &lt; nums[pos]){ pos = j; } } swap(nums[pos], nums[i]); }} 4 插入排序算法描述：分为已排序和未排序，初始已排序区间只有一个元素 就是数组第一个，遍历未排序的每一个元素，在已排序区间里找到合适的位置插入并保证数据一直有序。 12345678910void InsertSort(vector&lt;int&gt; &amp;nums){ int n = nums.size(); for (int i = 1; i &lt; n; ++i){ for (int j = i; j &gt; 0; --j){ if (nums[j] &lt; nums[j-1]){ swap(nums[j], nums[j-1]); } } }} 5 希尔排序算法描述：通过将比较的全部元素分为几个区域来提升插入排序的性能。这样可以让一个元素可以一次性地朝最终 位置前进一大步。然后算法再取越来越小的步长进行排序，算法的最后一步就是普通的插入排序，但是到了这步， 需排序的数据几乎是已排好的了。 1234567891011void ShellSort(vector&lt;int&gt; &amp;nums){ int n = nums.size(); for (int gap = n/2; gap &gt; 0; gap /= 2){ // 从index为gap的数开始插入，index在[0,gap-1]的数都是每组的第一个数 for (int i = gap; i &lt; n; ++i){ for (int j = i; j - gap &gt;= 0 &amp;&amp; nums[j-gap] &gt; nums[j]; j -= gap){ swap(nums[j], nums[j-gap]); } } }} 6 归并排序算法描述：归并排序是一种分治策略的排序算法。它是一种比较特殊的排序算法，通过递归地先使每个子序列有序，再将两个有序的序列进行合并成一个有序的序列。 123456789101112131415161718192021222324252627282930void MergeCount(vector&lt;int&gt; &amp;nums, int left, int mid, int right){ vector&lt;int&gt; tmp(right-left+1); int l = left, r = mid+1; int tmpIndex = 0; while(l &lt;= mid &amp;&amp; r &lt;= right){ if (nums[l] &lt; nums[r]){ tmp[tmpIndex++] = nums[l++]; }else{ tmp[tmpIndex++] = nums[r++]; } } while(l &lt;= mid){ tmp[tmpIndex++] = nums[l++]; } while(r &lt;= right){ tmp[tmpIndex++] = nums[r++]; } for (int i = left; i &lt;= right; ++i){ nums[i] = tmp[i-left]; }}void MergeSort(vector&lt;int&gt; &amp;nums, int left, int right){ if (left &gt;= right) return; int mid = left + (right-left)/2; MergeSort(nums, left, mid); MergeSort(nums, mid+1, right); MergeCount(nums, left, mid, right);} 7 快速排序算法描述：先找到一个标准，在原来的元素里根据这个标准划分比这个标准小的元素排前面，比这个标准大的元素 排后面，两部分数据依次递归排序下去直到最终有序。 12345678910111213void QuickSort(vector&lt;int&gt; &amp;nums, int left, int right){ if (left &gt;= right) return; int l = left + 1, r = right; while(l &lt; r){ while(l &lt; r &amp;&amp; nums[l] &lt;= nums[left]) { ++l; } if (l &lt; r) swap(nums[l], nums[r--]); while(l &lt; r &amp;&amp; nums[r] &gt;= nums[left]) { --r; } if (l &lt; r) swap(nums[l++], nums[r]); } swap(nums[left], nums[l]); QuickSort(nums, left, l-1); QuickSort(nums, l+1, right);} 8 堆排序算法描述：将待排序的序列构造成一个最大堆，此时序列的最大值为根节点。依次将根节点与待排序序列的最后一个元素交换。再维护从根节点到该元素的前一个节点为最大堆，如此往复，最终得到一个递增序列。 1234567891011121314151617181920212223242526272829void BuildHeap(vector&lt;int&gt; &amp;nums){ for (int i = 1; i &lt; nums.size(); ++i){ int temp = i; while(temp &gt; 0 &amp;&amp; nums[temp] &gt; nums[(temp-1)/2]){ swap(nums[temp], nums[(temp-1)/2]); temp = (temp-1)/2; } }}void Down(vector&lt;int&gt; &amp;nums, int i){ int maxPos = 0; while(1){ int index = maxPos; if (2*index+1 &lt;= i &amp;&amp; nums[2*index+1] &gt; nums[maxPos]){ maxPos = 2*index+1; } if (2*index+2 &lt;= i &amp;&amp; nums[2*index+2] &gt; nums[maxPos]){ maxPos = 2*index+2; } if (maxPos == index) break; swap(nums[maxPos], nums[index]); }}void HeapSort(vector&lt;int&gt; &amp;nums){ int n = nums.size(); BuildHeap(nums); for (int i = 1; i &lt; n; ++i){ swap(nums[0], nums[n-i]); Down(nums, n-i-1); }} 9 计数排序算法描述：需要知道待排序的数据的取值范围，使用辅助数组统计取值范围中取每个值的个数有几个，然后遍历取值范围输出。 123456789101112131415161718192021void CountSort(vector&lt;int&gt; &amp;nums){ int n = nums.size(), minNum = nums[0], maxNum = nums[0]; // 计算取值范围 for (int i = 1; i &lt; n; ++i){ minNum = min(minNum, nums[i]); maxNum = max(maxNum, nums[i]); } int k = maxNum-minNum+1; vector&lt;int&gt; count(k); // 统计每个值有几个 for (int i = 0; i &lt; n; ++i){ ++count[nums[i]-minNum]; } // 遍历统计数组输出 int sum = 0; for (int i = 0; i &lt; k; ++i){ for (int j = 0; j &lt; count[i]; ++j){ nums[sum++] = i+minNum; } }} 10 桶排序算法描述：将数组分到有限数量的桶里。每个桶再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）。和计数排序的区别主要是桶有限，计数排序的桶数目和取值范围一样。 假设数据是均匀分布的，则每个桶的元素平均个数为 $\\frac{n}{k}$。假设选择用快速排序对每个桶内的元素进行排序，那么每次排序的时间复杂度为 $O(\\frac{n}{k}log\\frac{n}{k})$ 。总的时间复杂度为： $O(n) +O(k)\\times O(\\frac{n}{k}log\\frac{n}{k}) = O(n+O(nlog\\frac{n}{k}))=O(n+nlogn-nlogk)$。 当 k 接近于 n 时，桶排序的时间复杂度就可以近似认为是 O(n) 的。即桶越多，时间效率就越高，而桶越多，空间就越大。 11 基数排序算法描述：基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系， 如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 $O(n)$ 了。 12345678910111213141516171819202122232425262728293031323334void BaseSort(vector&lt;int&gt; &amp;nums){ // 得到最大位数 int n = nums.size(), maxNum = nums[0]; int d = 0; // 最大位数 for (auto i : nums){ if (i &gt; maxNum){ maxNum = i; } } while(maxNum){ maxNum /= 10; ++d; } int factor = 1; // 从个位排到第d位 for (int i = 1; i &lt;= d; ++i){ vector&lt;int&gt; bucket[10]; // 初始化10个桶 for (int j = 0; j &lt; n; ++j){ int temp = (nums[j]/factor) % 10; bucket[temp].push_back(nums[j]); } int index = 0; // 遍历10个桶，按从小到大顺序放入原数组 for (int j = 0; j &lt; 10; ++j){ int s = bucket[j].size(); for (int k = 0; k &lt; s; ++k){ nums[index++] = bucket[j][k]; } bucket[j].clear(); // 桶置空 } factor *= 10; }} 参考： Algorithm：十大经典排序算法C++实现及总结_51CTO博客_c++排序算法 (56条消息) 基数排序、桶排序和计数排序的区别_计数排序和桶排序_Rnan-prince的博客-CSDN博客 (56条消息) 堆排序算法（图解详细流程）_堆排序的详细过程_阿顾同学的博客-CSDN博客","link":"/2023/04/11/%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"title":"剖析HTTPS","text":"本来只是想仔细研究一下https，不过既然要做了，那就把整个网站访问的包都分析一下吧。本文将详解在edge浏览器输入 https://oc.sjtu.edu.cn 会发生什么。 1 DNS显然，第一步得知道域名对应的IP地址，所以会发送DNS报文。 可以看到这里DNS报文都是两条两条发送回应的，原因应该是本人所处网络为IPV6环境，所以发送DNS报文时会发送一个IPV4版本的和一个IPV6版本的。 A（Address）记录指定域名对应的IP地址，更多类型可看DNS记录类型介绍(A记录、MX记录、NS记录等)-阿里云开发者社区 (aliyun.com)了解。 2 TCP既然知道了ip为202.120.35.235，这下可以对ip包进行筛选了，在wireshark使用ip.addr == 202.120.35.235即可 可以看到有两个TCP连接，这个蛮迷惑的，搜索后有一个解释为： 可以看到火狐浏览器中正常：一次请求只建立一次tcp连接。我们尝试了curl发起请求，抓包记录都是一次tcp连接。基本确定不是浏览器的共性，只是谷歌浏览器的个性。使用多个连接通常最容易想到的是加速访问，比如一个数据库连接不够用，可以建立多个连接（连接池复用连接）。 但是数据包还是好多，可以使用tcp.stream eq 3追踪一条tcp流 显然，数据包还是很多…… 前面是三次握手，没啥好说的。有一个点是来回的MSS不一样，这是在通告对方自己的MSS，然后取小的来。 3 TLSv1.2这是我真正想要关注的东西，再加一条tls过滤条件，数据包可以看到有四个tls协议包。 3.1 第一次握手Client Hello 首先可以看到这个是TLS握手协议 理论上来说，TLS主要分为两层，底层的是TLS记录协议，主要负责使用对称密码对消息进行加密；上层的是TLS握手协议，主要分为握手协议，密码规格变更协议、警告协议和应用数据协议4个部分。 握手协议负责在客户端和服务器端商定密码算法和共享密钥，包括证书认证，是4个协议中最最复杂的部分。 密码规格变更协议负责向通信对象传达变更密码方式的信号 警告协议负责在发生错误的时候将错误传达给对方 应用数据协议负责将TLS承载的应用数据传达给通信对象的协议。 [Client Hello] 给出了很多信息，包括 可用版本号 当前时间 客户端随机数 会话ID 可用的密码套件清单 可用的压缩方式清单 3.2 第二次握手Server Hello &amp; Certificate &amp; Server Hello Done 前面说过，握手协议包含四个部分，这里三个合并的消息都属于握手协议。 3.2.1 Server Hello回应了 [Client Hello] 消息，回复内容包括 使用的版本号 当前时间 服务端随机数 会话ID 使用的密码套件清单 使用的压缩方式清单 上图中服务端选择的算法套件是：TLS__RSA_WITH_AES_256_CBC_SHA (0x0035), 它的意思是： 密钥交换算法采用：RSA 签名算法采用：RSA 加密算法采用：AES对称算法，密钥长度为256bit, 模式为：CBC。 摘要算法采用：SHA 3.2.2 Certificate发送服务端证书，这里发了两张证书 3.2.3 Server Hello Done服务端发送 [Server Hello Done] 消息，告诉客户端，我已经把该给你的东西都给你了，本次打招呼完毕。 3.3 第三次握手Client Key Exchange &amp; Change Cipher Spec &amp; Encrypted Handshake Message 这三个消息分别属于握手协议、密码规格变更协议、握手协议。 3.3.1 Client Key Exchange客户端验证完证书后，认为可信则继续往下走。接着，客户端就会生成一个新的随机数 (pre-master)，用服务器的 RSA 公钥加密该随机数，通过 [Client Key Exchange] 消息传给服务端。 服务端收到后，用 RSA 私钥解密，得到客户端发来的随机数 (pre-master)。 至此，客户端和服务端双方都共享了三个随机数，分别是 Client Random、Server Random、pre-master。于是，双方根据已经得到的三个随机数，生成会话密钥（Master Secret），它是对称密钥，用于对后续的请求/响应的数据加解密。 3.3.2 Change Cipher Spec上一步生成了会话密钥，所以客户端发一个 **[Change Cipher Spec]**，告诉服务端开始使用加密方式发送消息。 3.3.3 Encrypted Handshake Message[Encrypted Handshake Message] 消息，把之前所有发送的数据做个摘要，再用会话密钥（master secret）加密一下，让服务器做个验证，验证加密通信是否可用和之前握手信息是否有被中途篡改过。 3.4 第四次握手Change Cipher Spec &amp; Encrypted Handshake Message 3.4.1 Change Cipher Spec服务端告诉客户端开始使用加密方式发送消息 3.4.2 Encrypted Handshake Message和3.3.3功能一样 4 番外4.1 DNS CNAME记录这里扯一下DNS CNAME记录，是在访问 www.baidu.com 时遇到的。 一个DNS CNAME记录将一个主机名映射到另一个。这意味着你可以有多个具有相同IP地址的主机，但每个主机都有一个不同的名字。CANME的好处是：在下图例子中，如果我调整了 Web 服务器，将它迁移到另一台主机上，我只需修改 webserver.fasionchan.com 一个域名，其他专栏域名均无须调整。 4.2 RSA算法的缺陷使用 RSA 密钥协商算法的最大问题是不支持前向保密。 因为客户端传递随机数（用于生成对称加密密钥的条件之一）给服务端时使用的是公钥加密的，服务端收到后，会用私钥解密得到随机数。所以一旦服务端的私钥泄漏了，过去被第三方截获的所有 TLS 通讯密文都会被破解。 为了解决这个问题，后面就出现了 ECDHE 密钥协商算法。 4.3 JA3和JA3S在 [Client Hello] 中包含一个字段叫 JA3 ，在**[Server Hello]** 中包含字段 JA3S，这两者是什么？ JA3(S) 是为特定客户端与服务器之间的加密通信提供了具有更高的识别度的指纹，说白了就是 TLS 协商的指纹。它的用处是识别恶意客户端和服务器之间的 TLS 协商。 例如，现在的 C2 服务器（Command and Control server，命令和控制服务器）与恶意客户端之间的通信往往都是套上 TLS 的，将其流量隐藏在噪声中来躲避 IDS/IPS（入侵检测/入侵预防），这样光从 ip/域名这个维度去检测难免会漏掉一些。如果我们掌握了 C2 服务器与恶意客户端的 JA3(S)，即使恶意流量被加密且不知道 C2 服务器的 IP 地址或域名，我们仍然可以通过 TLS 指纹来识别恶意客户端和服务器之间的 TLS 协商。 那么难道JA3(S)不能改变吗？当然是可以的，但是会提高成本：改个 ip 或者域名，比修改客户端程序方便多了。 JA3S 不能单独使用，必须与 JA3 结合使用才能更有效地进行检测或列入黑名单。当成对使用时，它还可以减少误报的数量。此外，如果我们只使用 JA3 指纹，我们很可能会看到稳定的流量，其中大部分是合规范的。JA3+JA3S 依旧不会非常准确，但是可以丰富我们检测威胁的维度，增加了攻击者的攻击成本。 参考： DNS记录类型介绍(A记录、MX记录、NS记录等)-阿里云开发者社区 (aliyun.com) 什么是DNS CNAME记录？CNAME记录的简易指南 (powerdmarc.com) DNS记录类型 | 小菜学网络 (fasionchan.com) (56条消息) 谷歌浏览器，一次get请求建立两次tcp连接_wireshark谷歌_码农小麦的博客-CSDN博客 (99+ 封私信 / 80 条消息) 为什么TCP的MSS协商没有按照小的来？ - 知乎 (zhihu.com) 3.3 HTTPS RSA 握手解析 | 小林coding (xiaolincoding.com) JA3(S)，简单而有效的 TLS 指纹 - Tr0y’s Blog C2 - katago - 博客园 (cnblogs.com)","link":"/2023/04/14/%E5%89%96%E6%9E%90HTTPS/"},{"title":"线程间共享数据","text":"1 使用互斥量保护共享数据互斥量是C++中一种最通用的数据保护机制，但是依旧需要精心组织代码，否则会造成死锁。 1.1 C++中使用互斥量C++中通过实例化std::mutex创建互斥量，通过调用成员函数lock()进行上锁，unlock()进行解锁。在实践中，C++标准库为互斥量提供了一个RAII语法的模板类std::lock_guard，其会在构造的时候提供已锁的互斥量，并在析构的时候进行解锁，从而保证了一个已锁的互斥量总是会被正确的解锁。 但是，当其中一个成员函数返回的是保护数据的指针或引用时，会破坏对数据的保护。具有访问能力的指针或引用可以访问(并可能修改)被保护的数据，而不会被互斥锁限制。互斥量保护的数据需要对接口的设计相当谨慎，要确保互斥量能锁住任何对保护数据的访问，并且不留后门。 1.2 死锁一般解决方案避免死锁的一般建议，就是让两个互斥量总以相同的顺序上锁：总在互斥量B之前锁住互斥量A，就永远不会死锁。某些情况下是可以这样用，因为不同的互斥量用于不同的地方。不过，事情没那么简单，比如：当有多个互斥量保护同一个类的独立实例时，一个操作对同一个类的两个不同实例进行数据的交换操作，为了保证数据交换操作的正确性，就要避免数据被并发修改，并确保每个实例上的互斥量都能锁住自己要保护的区域。不过，选择一个固定的顺序(例如，实例提供的第一互斥量作为第一个参数，提供的第二个互斥量为第二个参数)，可能会适得其反：在参数交换了之后，两个线程试图在相同的两个实例间进行数据交换时，程序又死锁了！ C++标准库有办法解决这个问题，std::lock——可以一次性锁住多个(两个以上)的互斥量，并且没有副作用(死锁风险)。下面的程序清单展示了怎么在一个简单的交换操作中使用std::lock。 123456789101112131415161718192021class X{ private: some_big_object some_detail; std::mutex m; public: void swap(X&amp; lhs, X&amp; rhs){ if(&amp;lhs==&amp;rhs) return; // adopt_lock 要求调用线程当前拥有锁 std::lock(lhs.m, rhs.m); std::lock_guard&lt;std::mutex&gt; lock1(lhs.m, std::adopt_lock); std::lock_guard&lt;std::mutex&gt; lock2(rhs.m, std::adopt_lock); // 等价方法： // std::unique_lock&lt;std::mutex&gt; lock1(lhs.m, std::defer_lock); // std::unique_lock&lt;std::mutex&gt; lock2(rhs.m, std::defer_lock); // std::lock(lock1, lock2); swap(lhs.some_detail,rhs.some_detail); }}; 2 原子类型与原子操作2.1 原子类型与原子操作C++11通过引入原子类型帮助开发者轻松实现原子操作。 123456789101112131415161718192021222324#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;iostream&gt;using namespace std;atomic_int64_t total = 0; //atomic_int64_t相当于int64_t，但是本身就拥有原子性//线程函数，用于累加void threadFunc(int64_t endNum){ for (int64_t i = 1; i &lt;= endNum; ++i){ total += i; }}int main(){ int64_t endNum = 100; thread t1(threadFunc, endNum); thread t2(threadFunc, endNum); t1.join(); t2.join(); cout &lt;&lt; &quot;total=&quot; &lt;&lt; total &lt;&lt; endl; //10100} 原子类型C++11中通过atomic&lt;T&gt;类模板来定义，比如atomic_int64_t是通过typedef atomic&lt;int64_t&gt; atomic_int64_t实现的，使用时需包含头文件&lt;atomic&gt;。除了提供atomic_int64_t，还提供了其它的原子类型。常见的原子类型有： 原子类型名称 对应内置类型 atomic_bool bool atomic_char atomic_char atomic_char signed char atomic_uchar unsigned char atomic_short short atomic_ushort unsigned short atomic_int int atomic_uint unsigned int atomic_long long atomic_ulong unsigned long atomic_llong long long atomic_ullong unsigned long long atomic_ullong unsigned long long atomic_char16_t char16_t atomic_char32_t char32_t atomic_wchar_t wchar_t 原子操作是平台相关的，原子类型能够实现原子操作是因为C++11对原子类型的操作进行了抽象，定义了统一的接口，并要求编译器产生平台相关的原子操作的具体实现。C++11标准将原子操作定义为atomic模板类的成员函数，包括读（load）、写（store）、交换（exchange）等。对于内置类型而言，主要是通过重载一些全局操作符来完成的。比如对上文total+=i的原子加操作，是通过对operator+=重载来实现的。使用g++编译的话，在x86_64的机器上，operator+=()函数会产生一条特殊的以lock为前缀的x86_64指令，用于控制总线及实现x86_64平台上的原子性加法。 另外，列表中有一个比较特殊的atomic_flag类型，atomic_flag与其他类型不同，它是无锁(lock_free)的，而其他的类型不一定是无锁的。因为，atomic&lt;T&gt;并不能保证类型T是无锁的，另外不同平台的处理器处理方式不同，也不能保证必定无锁，所以其他的类型都会有is_lock_free来判断是否是无锁的。atomic_flag只支持test_and_set以及clear两个成员函数，test_and_set函数检查 std::atomic_flag 标志，如果 std::atomic_flag 之前没有被设置过，则设置 std::atomic_flag 的标志，并返回先前该 std::atomic_flag 对象是否被设置过，如果之前 std::atomic_flag 对象已被设置，则返回 true，否则返回 false；clear函数清除 std::atomic_flag 标志使得下一次调用 std::atomic_flag::test_and_set 返回 false。可以用这两个函数来实现一个自旋锁： 12345678910111213141516171819202122232425262728293031#include &lt;unistd.h&gt;#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;iostream&gt;std::atomic_flag lock = ATOMIC_FLAG_INIT;void func1(){ while (lock.test_and_set(std::memory_order_acquire)) // 在主线程中设置为true，需要等待t2线程clear { std::cout &lt;&lt; &quot;func1 wait&quot; &lt;&lt; std::endl; } std::cout &lt;&lt; &quot;func1 do something&quot; &lt;&lt; std::endl;}void func2(){ std::cout &lt;&lt; &quot;func2 start&quot; &lt;&lt; std::endl; lock.clear();}int main(){ lock.test_and_set(); // 设置状态 std::thread t1(func1); sleep(1); //睡眠1us std::thread t2(func2); t1.join(); t2.join(); return 0;} 以上代码中，线程t1调用test_and_set一直返回true(因为在主线程中被设置过)，所以一直在等待，而等待一段时间后当线程t2运行并调用了clear，test_and_set返回了false退出循环等待并进行相应操作。这样一来，就实现了一个线程等待另一个线程的效果。当然，可以封装成锁操作的方式，比如： 12void Lock(atomic_flag&amp; lock){ while ( lock.test_and_set()); }void UnLock(atomic_flag&amp; lock){ lock.clear(); } 这样一来，就可以通过Lock()和UnLock()的方式来互斥地访问临界区。 2.2 内存模型、顺序一致性和memory_order内存模型是一个硬件上的概念,表示机器指令是以什么样的顺序被处理器执行的 (现代的处理器不是逐条处理机器指令的) 。C++11中顺序一致性只是多种内存模型中的一种，代码并非必须按照顺序执行，因为顺序往往意味着最低效的同步方式，现代的处理器并不是逐条处理机器指令的。高级语言和机器指令是通过编译器来进行转换的，而编译器处于代码优化的考虑，会将指令进行移动。对于C++11的内存模型而言，要保证代码的顺序一致性，需要同时做到以下几点： 编译器保证原子操作的指令间顺序不变，即产生的读写原子类型变量的机器指令和代码编写顺序是一样的。 处理器对原子操作的汇编指令的执行顺序不变。这对于x86这样的强顺序的体系结构而言没有任何问题，而对于一些弱顺序的平台则需要原子操作之后要加入内存栅栏。 对于一些代码来说，如果只需要在主线程中打印结果，那么代码的执行顺序并不重要。但是atomic原子类型默认的顺序一致性会要求编译器禁用优化，这无疑增加了性能开销。于是C++11中，设计了能够对原子类型指定内存顺序memory_order。 1234567891011// 原始代码void func1(){ a = 1; b = 2;}// 改进代码void func1(){ a.store(1, std::memory_order_relaxed); b.store(2, std::memory_order_relaxed);} 上面的代码使用了store函数进行赋值，store函数接受两个参数，第一个是要写入的值，第二个是名为memory_order的枚举值。这里使用了std::memory_order_relaxed，表示松散内存顺序，该枚举值代表编译器可以任由编译器重新排序或则由处理器乱序处理。这样a和b的赋值执行顺序性就被解除了。在C++11中一共有6种memory_order枚举值，默认按照memory_order_seq_cst执行： 枚举值 定义规则 memory_order_relaxed 不对执行顺序做保证 memory_order_acquire 本线程中,所有后续的读操作必须在本条原子操作完成后执行 memory_order_release 本线程中,所有之前的写操作完成后才能执行本条原子操作 memory_order_acq_rel 同时包含memory_order_acquire和memory_order_release memory_order_consume 本线程中,所有后续的有关本原子类型的操作,必须在本条原子操作完成之后执行 memory_order_seq_cst 全部存取都按顺序执行 需要注意的是，不是所有的memory_order都能被atomic成员使用： store函数可以使用memory_order_seq_cst、memory_order_release、memory_order_relaxed。 load函数可以使用memory_order_seq_cst、memory_order_acquire、memory_order_consume、memory_order_relaxed。 需要同时读写的操作，例如test_and_flag、exchange等操作。可以使用memory_order_seq_cst、memory_order_rel、memory_order_release、memory_order_acquire、memory_order_consume、memory_order_relaxed。 原子类型提供的一些操作符都是memory_order_seq_cst的封装，所以他们都是顺序一致性的。 最后说明一下，std::atomic和std::memory_order只有在多cpu多线程情况下，无锁编程才会用到。在x86下，由于是strong memory order的，所以很多时候只需要考虑编译器优化；保险起见，可以用std::atomic，他会同时处理编译器优化和cpu的memory order（虽然x86用不到）。但是在除非必要的情况下，不用使用std::memory_order，std::atmoic默认用的是最强限制。 2.3 内存栅栏C++中提供了两种栅栏，内存栅栏（atomic_thread_fence）用于解决线程之间表现的内存乱序，其阻止CPU指令层面的乱序优化；编译栅栏（atomic_signal_fence）用于解决与信号处理程序（一种软中断程序）之间表现的内存乱序，其仅阻止编译器层面的乱序优化，不产生内存屏障指令。（内存屏障是一类同步屏障指令，是CPU或者编译器在对内存随机访问的操作中的一个同步点，只有在此点之前的所有读写操作都执行后才可以执行此点之后的操作。） 1234//C++内存栅栏的函数定义：extern &quot;C&quot; void atomic_thread_fence(std::memory_order order) noexcept;//C++编译栅栏的函数定义：extern &quot;C&quot; void atomic_signal_fence(std::memory_order order) noexcept; 2.4 使用atomic_flag实现一个自旋锁1234567891011121314class spin_lock final{public: void lock() { while (flag.test_and_set(memory_order_acquire)); } void unlock() { flag.clear(memory_order_release); }private: atomic_flag flag;}; 参考： C++并发编程(中文版)（C++ Concurrency In Action） C++11原子类型与原子操作 - 腾讯云开发者社区-腾讯云 (tencent.com) (56条消息) 《深入理解C++11》笔记-原子类型和原子操作_WizardtoH的博客-CSDN博客 (56条消息) 处理器协同机制其三C++内存顺序与栅栏（及依赖性读屏障）_c++ 栅栏_一念之卓的博客-CSDN博客 (57条消息) 自旋锁的实现及优化_自旋锁实现_柴郡猫乐园的博客-CSDN博客","link":"/2023/04/17/%E7%BA%BF%E7%A8%8B%E9%97%B4%E5%85%B1%E4%BA%AB%E6%95%B0%E6%8D%AE/"},{"title":"基于锁的并发数据结构(C++)","text":"1 线程安全栈首先看看 std::stack 容器的实现 12345678910111213141516171819template&lt;typename T,typename Container=std::deque&lt;T&gt; &gt;class stack{public: explicit stack(const Container&amp;); explicit stack(Container&amp;&amp; = Container()); template &lt;class Alloc&gt; explicit stack(const Alloc&amp;); template &lt;class Alloc&gt; stack(const Container&amp;, const Alloc&amp;); template &lt;class Alloc&gt; stack(Container&amp;&amp;, const Alloc&amp;); template &lt;class Alloc&gt; stack(stack&amp;&amp;, const Alloc&amp;); bool empty() const; size_t size() const; T&amp; top(); T const&amp; top() const; void push(T const&amp;); void push(T&amp;&amp;); void pop(); void swap(stack&amp;&amp;);}; stack 是以deque 做为底部结构， 将其接口改变，使得其符合先进后出的特点。deque 是双向开口的数据结构，将deque 封闭其头端开口，便形成了stack, 因此便以 deque 作为缺省情况下的stack 底部结构。 在单线程下，上面的stack是安全的，但是在多线程下的情况是如何的呢？ 首先来看下面一段代码： 123456stack&lt;int&gt; s;if (!s.empty()){ // 1 int const value = s.top(); // 2 s.pop(); // 3 do_something(value);} 以上是单线程安全代码：对一个空栈使用top()是未定义行为。对于共享的栈对象，这样的调用顺序就不再安全了，因为在调用empty()①和调用top()②之间，可能有来自另一个线程的pop()调用并删除了最后一个元素。这是一个经典的条件竞争，使用互斥量对栈内部数据进行保护，但依旧不能阻止条件竞争的发生，这就是接口固有的问题。怎么解决呢？问题发生在接口设计上，所以解决的方法也就是改变接口设计。怎么改？在这个简单的例子中，当调用top()时，发现栈已经是空的了，那么就抛出异常。虽然这能直接解决这个问题，但这是一个笨拙的解决方案，这样的话，即使empty()返回false的情况下，你也需要异常捕获机制。本质上，这样的改变会让empty()成为一个多余函数。 仔细观察代码，就会发现另一个潜在的条件竞争在调用top()②和pop()③之间，假设两个线程运行前面的代码。并且都引用同一个对象stacks。假设，一开始栈中只有两个元素，这时任一线程上的empty()和top()都存在竞争，只需要考虑可能的执行顺序即可。当栈被一个内部互斥量所保护时，只有一个线程可以调用栈的成员函数，所以调用可以很好地交错，并且do_something()是可以并发运行的。在下表中，展示一种可能的执行顺序。 Thread A Thread B if (!s.empty); if(!s.empty); int const value = s.top(); int const value = s.top(); s.pop(); do_something(value); s.pop(); do_something(value); 当线程运行时，调用两次top()，栈没被修改，所以每个线程能得到同样的值。不仅是这样，在调用top()函数调用的过程中(两次)，pop()函数都没有被调用。这样，在其中一个值再读取的时候，虽然不会出现“写后读”的情况，但其值已被处理了两次。这种条件竞争，比未定义的empty()/top()竞争更加严重；虽然其结果依赖于do_something()的结果，但因为看起来没有任何错误，就会让这个Bug很难定位。 解决方案：基本思想就是将 top() 和pop() 这两个操作合成一步操作。 另外还有问题，假设有一个stack&lt;vector&lt;int&gt;&gt;，vector是一个动态容器，当你拷贝一个vetcor，标准库会从堆上分配很多内存来完成这次拷贝。当这个系统处在重度负荷，或有严重的资源限制的情况下，这种内存分配就会失败，所以vector的拷贝构造函数可能会抛出一个std::bad_alloc异常。当vector中存有大量元素时，这种情况发生的可能性更大。当pop()函数返回“弹出值”时(也就是从栈中将这个值移除)，会有一个潜在的问题：这个值被返回到调用函数的时候，栈才被改变；但当拷贝数据的时候，调用函数抛出一个异常会怎么样？ 如果事情真的发生了，要弹出的数据将会丢失；它的确从栈上移出了，但是拷贝失败了！std::stack的设计人员将这个操作分为两部分：先获取顶部元素(top())，然后从栈中移除(pop())。这样，在不能安全的将元素拷贝出去的情况下，栈中的这个数据还依旧存在，没有丢失。当问题是堆空间不足，应用可能会释放一些内存，然后再进行尝试。 方案1： 传入一个引用 第一个方案是将变量的引用作为参数，传入pop()函数中获取想要的“弹出值”： 12std::vector&lt;int&gt; result;some_stack.pop(result); 大多数情况下，这种方式还不错，但有明显的缺点：需要构造出一个栈中类型的实例，用于接收目标值。对于一些类型，这样做是不现实的，因为临时构造一个实例，从时间和资源的角度上来看，都是不划算。对于其他的类型，这样也不总能行得通，因为构造函数需要的一些参数，在代码的这个阶段不一定可用。最后，需要可赋值的存储类型，这是一个重大限制：即使支持移动构造，甚至是拷贝构造(从而允许返回一个值)，很多用户自定义类型可能都不支持赋值操作。 方案2：返回指向弹出值的指针 第二个方案是返回一个指向弹出元素的指针，而不是直接返回值。指针的优势是自由拷贝，并且不会产生异常， 缺点就是返回一个指针需要对对象的内存分配进行管理，对于简单数据类型(比如：int)，内存管理的开销要远大于直接返回值。对于选择这个方案的接口，使用std::shared_ptr是个不错的选择；不仅能避免内存泄露(因为当对象中指针销毁时，对象也会被销毁)，而且标准库能够完全控制内存分配方案，也就不需要new和delete操作。这种优化是很重要的：因为堆栈中的每个对象，都需要用new进行独立的内存分配，相较于非线程安全版本，这个方案的开销相当大。 下面给出一个线程安全的stack，它实现了方案1和方案2：重载了pop()，使用一个局部引用去存储弹出值，并返回一个std::shared_ptr&lt;&gt;对象。它有一个简单的接口，只有两个函数：push()和pop()。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;exception&gt;#include &lt;mutex&gt;#include &lt;memory&gt;struct empty_stack: std::exception{ const char* what() const throw();};template&lt;typename T&gt;class threadsafe_stack{ private: std::stack&lt;T&gt; st; mutable std::mutex m; public: threadsafe_stack(){} threadsafe_stack(const threadsafe_stack&amp; other){ std::lock_guard&lt;std::mutex&gt; lock(other.m); st = other.st; } threadsafe_stack&amp; operator=(const threadsafe_stack&amp;) = delete; void push(T new_value){ std::lock_guard&lt;std::mutex&gt; lock(m); st.push(std::move(new_value)); } std::shared_ptr&lt;T&gt; pop(){ std::lock_guard&lt;std::mutex&gt; lock(m); if (st.empty()) throw empty_stack(); std::shared_ptr&lt;T&gt; const res(std::make_shared&lt;T&gt;(std::move(st.top()))); st.pop(); return res; } void pop(T&amp; value){ std::lock_guard&lt;std::mutex&gt; lock(m); if (st.empty()) throw empty_stack(); value = std::move(st.top()); st.pop(); } bool empty() const{ std::lock_guard&lt;std::mutex&gt; lock(m); return st.empty(); }} 2 线程安全队列std::queue&lt;&gt; 容器的接口展示如下： 123456789101112131415161718192021template &lt;class T, class Container = std::deque&lt;T&gt; &gt;class queue {public: explicit queue(const Container&amp;); explicit queue(Container&amp;&amp; = Container()); template &lt;class Alloc&gt; explicit queue(const Alloc&amp;); template &lt;class Alloc&gt; queue(const Container&amp;, const Alloc&amp;); template &lt;class Alloc&gt; queue(Container&amp;&amp;, const Alloc&amp;); template &lt;class Alloc&gt; queue(queue&amp;&amp;, const Alloc&amp;); void swap(queue&amp; q); bool empty() const; size_type size() const; T&amp; front(); const T&amp; front() const; T&amp; back(); const T&amp; back() const; void push(const T&amp; x); void push(T&amp;&amp; x); void pop(); template &lt;class... Args&gt; void emplace(Args&amp;&amp;... args);}; 当你忽略构造、赋值以及交换操作时，你就剩下了三组操作： 对整个队列的状态进行查询(empty()和size()) 查询在队列中的各个元素(front()和back()) 修改队列的操作(push(), pop()和emplace()) 因此你也会遇到在固有接口上的条件竞争。你需要将front()和pop()合并成一个函数调用，就像之前在栈实现时合并top()和pop()一样。 不同的是：当使用队列在多个线程中传递数据时，接收线程通常需要等待数据的压入。这里我们提供pop()函数的两个变种：try_pop()和wait_and_pop()。try_pop() ，尝试从队列中弹出数据，总会直接返回(当有失败时)，即使没有值可检索；wait_and_pop()，将会等待有值可检索的时候才返回。当你使用之前栈的方式来实现你的队列，你实现的队列就可能会是下面这样： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;queue&gt;#include &lt;memory&gt;#include &lt;mutex&gt;#include &lt;condition_variable&gt;template&lt;typename T&gt;class threadsafe_queue{ private: mutable std::mutex m; // 1 互斥量必须是可变的 std::queue&lt;T&gt; que; std::condition_variable data_cond; public: threadsafe_queue(){} threadsafe_queue(threadsafe_queue const&amp; other){ std::lock_guard&lt;std::mutex&gt; lock(other.m); que = other.que; } void push(T new_value){ std::lock_guard&lt;std::mutex&gt; lock(m); que.push(new_value); data_cond.notify_one(); } void wait_and_pop(T&amp; value){ std::unique_lock&lt;std::mutex&gt; lock(m); data_cond.wait(lock,[this]{return !que.empty();}); value = que.front(); que.pop(); } std::shared_ptr&lt;T&gt; wait_and_pop(){ std::unique_lock&lt;std::mutex&gt; lock(m); data_cond.wait(lock,[this]{return !que.empty();}); std::shared_ptr&lt;T&gt; res(std::make_shared&lt;T&gt;(que.front())); que.pop(); return res; } bool try_pop(T&amp; value){ std::lock_guard&lt;std::mutex&gt; lock(m); if(que.empty()) return false; value=que.front(); que.pop(); return true; } std::shared_ptr&lt;T&gt; try_pop(){ std::lock_guard&lt;std::mutex&gt; lock(m); if(que.empty()) return std::shared_ptr&lt;T&gt;(); std::shared_ptr&lt;T&gt; res(std::make_shared&lt;T&gt;(que.front())); que.pop(); return res; } bool empty() const{ std::lock_guard&lt;std::mutex&gt; lock(m); return que.empty(); }}; 第3章 线程间共享数据 - 3.2 使用互斥量保护共享数据 - 《C++并发编程(中文版)（C++ Concurrency In Action）》 - 书栈网 · BookStack (56条消息) 多线程编程– 线程安全的栈 stack_deanlan_sjtu的博客-CSDN博客","link":"/2023/04/18/%E5%9F%BA%E4%BA%8E%E9%94%81%E7%9A%84%E5%B9%B6%E5%8F%91%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-C/"},{"title":"无锁数据结构-栈(C++)","text":"1 无锁数据结构的优点和缺点优点: 最大限度实现并发：在基于锁的容器上，若某个线程还未完成操作，就大有可能阻塞另一线程，使之陷入等待而无法处理；而且，互斥锁的根本意图是杜绝并发功能。在无锁数据结构上，总是存在某个线程能执行下一操作。 代码的健壮性：假设数据结构的写操作受锁保护，如果线程在持锁期间终止，那么该数据结构只完成了部分改动，且此后无从修补。但是（无锁数据结构），若某线程操作无锁数据时意外终结，则丢失的数据仅限于它持有的部分，其他数据依然完好，能被别的线程正常处理。无锁数据结构不含锁，因此不会出现死锁。 缺点： 难度大：对线程安全的无锁数据结构执行写操作，难度远远高于对带锁的数据结构体执行写操作。需留心施加在各项操作上的内存次序约束。 活锁：由于无锁数据结构完全不含锁，因此不可能出现死锁，但活锁反而有机会出现。假设两个线程同时修改同一份数据结构，若他们所做的改动都导致对方从头开始操作，那双方就会反复循环，不断重试，这种现象即为活锁。活锁出现与否完全取决于线程的调度次序，故往往只会短暂存在。因此，它们虽然降低了程序性能，尚不至于造成严重的问题，但我们仍需小心防范。 降低整体性能：即便没有其他线程同时访问数据机头，也依然要执行更多步骤。所以，虽然它提高了操作同一个数据结构的并发程度，缩短了单个线程因等待而消耗的时间，却有可能降低整体性能。首先对比原子操作，无锁代码所采用的原子操作要缓慢很多。对于基于锁的数据结构，其原子操作仅涉及互斥的加锁行为，相比之下，无锁数据结构种原子操作的数据可能更多。 2 无锁栈2.1 简介 栈容器能加入数据，然后按逆序取出——先进后出（后进先出——last in,fist out,LIFO). 因此，我们必须保证，一旦某线程将一项数据加入栈容器，就能立即安全的被另一个线程取出，同时还得保证，只有唯一一个线程能获取该项数据。 最简单的栈容器可以通过链表的形式实现：指针head指向第一个节点，各节点内的next成员指针再依次指向后继节点。 2.2 无锁栈原理图 2.3 添加节点（push）步骤1：创建新节点。步骤2：令新节点的成员指针next指向当前的头节点。步骤3：把head指针指向新节点。 但是这里有个问题，当有两个线程同时添加节点的时候，在第2步和第3步的时候会产生条件竞争：一个线程可能在修改head的值时，另一个线程正在执行第2步，并且在第3步中对head进行更新。这就会使之前那个线程的工作被丢弃，亦或是造成更加糟糕的后果。在了解如何解决这个条件竞争之前，还要注意一个很重要的事：当head更新，并指向了新节点时，另一个线程就能读取到这个节点了。因此，在head设置为指向新节点前，让新节点完全准备就绪就变得很重要了；因为，在这之后就不能对节点进行修改了。 那如何应对讨厌的条件竞争呢？答案就是：在第3步的时候使用一个原子“比较/交换”操作，来保证当步骤2对head进行读取时，不会对head进行修改。当有修改时，可以循环“比较/交换”操作。下面的代码就展示了，不用锁来实现线程安全的push()函数。 1234567891011121314151617181920template&lt;typename T&gt;class lock_free_stack{ private: struct node{ T value; node* next; node(T const&amp; data_) :value(data_), next(nullptr) {} }; std::atomic&lt;node*&gt; m_head; public: lock_free_stack(){ m_head.store(nullptr); }; void push(T const&amp; data){ node* const new_node = new node(data); new_node-&gt;next = m_head.load(); while (!m_head.compare_exchange_weak(new_node-&gt;next, new_node)); }}; 我们可以注意到一个非常巧妙的设计。在push方法里，atomic_compare_exchange_weak如果失败，证明有其他线程更新了栈顶，而这个时候被其他线程更新的新栈顶值会被更新到new_node-&gt;next中，因此循环可以直接再次尝试压栈而无需由程序员更新new_node-&gt;next。 2.4 弹出数据（pop）步骤1：读取当前head指针的值。 步骤2：读取head-&gt;next。 步骤3：设置head到head-&gt;next。 步骤4：通过索引node，返回data数据。 步骤5：删除索引节点。 但在多线程环境下，就不像看起来那么简单了。当有两个线程要从栈中移除数据，两个线程可能在步骤1中读取到同一个head(值相同)。当其中一个线程处理到步骤5，而另一个线程还在处理步骤2时，这个还在处理步骤2的线程将会解引用一个悬空指针。这只是写无锁代码所遇到的最大问题之一，所以现在只能跳过步骤5，让节点泄露。 另一个问题就是：当两个线程读取到同一个head值，他们将返回同一个节点。这就违反了栈结构的意图，所以你需要避免这样的问题产生。你可以像在push()函数中解决条件竞争那样来解决这个问题：使用“比较/交换”操作更新head。当“比较/交换”操作失败时，不是一个新节点已被推入，就是其他线程已经弹出了想要弹出的节点。无论是那种情况，都得返回步骤1(“比较/交换”操作将会重新读取head)。当“比较/交换”成功，就可以确定当前线程是弹出给定节点的唯一线程，之后就可以放心的执行步骤4了。 带有节点泄露的无锁栈 1234567891011121314151617181920212223242526template&lt;typename T&gt;class lock_free_stack{ private: struct node{ T value; node* next; node(T const&amp; data_) :value(data_), next(nullptr) {} }; std::atomic&lt;node*&gt; m_head; public: lock_free_stack(){ m_head.store(nullptr); }; void push(T const&amp; data){ node* const new_node = new node(data); new_node-&gt;next = m_head.load(); while (!m_head.compare_exchange_weak(new_node-&gt;next, new_node)); } void pop(T&amp; result){ node* old_head = m_head.load(); while(old_head &amp;&amp; !m_head.compare_exchange_weak(old_head, old_head-&gt;next)); result = old_head ? old_head-&gt;value : std::shared_ptr&lt;T&gt;(); }}; 2.5 使用线程个数计数法来管理内存释放问题那什么时候才能删除这个old_head呢？？必须是当只有一个线程引用这个对象时，才能释放它，如果有多个线程都拥有此对象，则不能释放，要延迟释放。由于push()函数在将节点加入到栈中之前，始终只有一个线程拥有新建的节点，因此push()函数无需处理，很安全。对于pop()函数而言，某个线程在执行完while循环之前，另一个线程也进入了pop()函数，那么就会出现同一个head被两个线程共享的情况。一旦线程执行完while循环后，其他线程再进入pop()函数，就安全了。因为一旦执行完成while之后，栈的head节点就变了，旧的old_head就已经脱离栈了，old_head只被当前线程所拥有，其他线程都拿不到当前线程的old_head了，其他线程的old_head已经是其他的对象了(被当前线程的compare_exchange_weak()函数给改变了)。此时当前线程就可以随意处理本线程的old_head了，这个时候释放old_head就百分百安全了。 那怎么才能安全删除呢？ 有种方法是将这些摘除的节点存放到一个待删除列表里面，当只有一个线程执行pop()函数时，一次性将这些待删除的节点一起删除。如何才能知道当前只有一个线程在执行pop()函数呢？当然使用计数方法啦！在pop()函数的入口处对一个全局原子变量进行递增，在离开时递减即可。我们先看看这种方案的一种实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121template &lt;typename T&gt;class lock_free_stack{private: struct node { std::shared_ptr&lt;T&gt; data; node* next; node(const T&amp; value) : data(std::make_shared&lt;T&gt;(value)), next(nullptr) {} };private: std::atomic&lt;node*&gt; head; std::atomic&lt;unsigned&gt; threads_in_pop; std::atomic&lt;node*&gt; to_be_deleted;private: static void delete_nodes(node* nodes) { while (nodes) { node* next = nodes-&gt;next; delete nodes; nodes = next; } } void chain_pending_nodes(node* first, node* last) { // 将last节点接到待删除链表的最前面，这里其实是假设first和last是另外一个链表， // 然后这里是把另外一个链表插入到已有链表的前面。 // 注意，有可能有多个线程在同时执行chain_pending_nodes，所以下面用到了原子操作 // 这两句语句很通用呀，并发插入节点的操作，非常好！！ last-&gt;next = to_be_deleted; // 9 while (!to_be_deleted.compare_exchange_weak(last-&gt;next, first)); // 10 } void chain_pending_node(node* n) { // 当只插入一个节点时，last与first是同一个节点 chain_pending_nodes(n, n); } void chain_pending_nodes(node* nodes) { // 找出被剥离出来的待删除链表的头和尾，然后再插回到to_be_deleted链表里 node* last = nodes; while (node* next = last-&gt;next) // 8 { last = next; } chain_pending_nodes(nodes, last); } void try_reclaim(node* old_head) { // 如果pop函数中执行完while循环后threads_in_pop还是1，表示pop中在执行while循环前一定没有其他线程进入pop， // 表示当前线程的这个old_head一定只被一个线程共享，即使后面threads_in_pop不再为1 if (threads_in_pop == 1) { node* nodes_to_delete = to_be_deleted.exchange(nullptr); // 4 if (!--threads_in_pop) // 5 { // 如果执行到为nodes_to_delete初始化后还是1，则此时就可以删除之前所有的待删除节点，因为那些待删除节点 // 一定没有被其他线程共享了 delete_nodes(nodes_to_delete); } else if (nodes_to_delete) // 6 { // 如果在为nodes_to_delete初始化后threads_in_pop已经不再是1，表示本线程在执行try_reclaim期间，其他 // 线程也进入了pop函数，此时，如果另一个线程还未执行到try_reclaim函数，则本线程其实可以直接结束并删除 // old_head节点的。但是这里是为了防止另外一种情况发生，就是另一个线程可能也已经执行到了try_reclaim函数， // 并发现threads_in_pop不为1(注意，上面的--threads_in_pop非常的细，这样做的话，如果另外只有一个线程也 // 同时进入了try_reclaim函数，则threads_in_pop还是为1，则另一个线程也可以直接删除它自己的old_head，跟 // 本线程无关)，说明除了本线程已经执行到了这里外，还有另外至少2个线程也在同时执行，然后另一个线程就会执行 // 下面的else语句，并将线程b的old_head存储到待删除链表中。那么，此时，我们在线程a中还不能删除那些在待删除链 // 表中的节点，又由于上面我们已经把部分待删除节点与to_be_deleted脱钩了，而现在暂时又不能删除nodes_to_delete， // 所以这里还得把这些已经脱钩了的待删除节点给接回去才行，等下次机会合适的时候再一起删除。 chain_pending_nodes(nodes_to_delete); } // 所以这里就可以直接delete掉了 delete old_head; } else { // 如果threads_in_pop不为1，说明有其他线程也在执行pop，由于不清楚其他线程是在本线程执行完pop中的while语句之后 // 开始执行的还是在执行while语句之前就已经开始执行的，因此无法确定本线程的old_head是否已经被其他线程所共享，所以 // 这里统一认为是被共享的，因此就将此old_head节点存储到待删除链表里，等待时机全部删除。 chain_pending_node(old_head); // 7 --threads_in_pop; } }public: void push(const T&amp; new_value) { node* new_node = new node(new_value); new_node-&gt;next = head; while (!head.compare_exchange_weak(new_node-&gt;next, new_node)); } std::shared_ptr&lt;T&gt; pop() { ++threads_in_pop; // 1 node* old_node = head.load(); while (old_node &amp;&amp; !head.compare_exchange_weak(old_node, old_node-&gt;next)); std::shared_ptr&lt;T&gt; res; if (old_node) { res.swap(old_node-&gt;data); // 2 try_reclaim(old_node); // 3 } return res; }}; 首先，我们看pop()里面的改动，现在在函数入口处加了一个threads_in_pop，然后代码2和3处也有改动。注意2处用的是swap()，比直接用赋值语句好，因为放入到待删除列表中的节点已经不需要获取其data数据了(其实其next数据也可以不需要了，因为虽然其他线程可能会将next作为第二个实参传给compare_exchange_weak，但是肯定会执行失败，从而就会将old_head重新更新为新的head。因而再次循环时next数据就正常了。为啥肯定会执行失败呢，因为此节点已经属于待删除节点了，说明已经有一个线程执行完了while循环并更新了head节点，然后才会将old_head放入到待删除链表里，所以head一定已经被更新过了的)。所以可以直接将待删除节点中的数据提取出来，不需要对其加一个引用了。然后再看3处，这里直接将待删除节点传给try_reclaim()函数尝试回收内存。注意，书上这里写错了，书上把try_reclaim()放到了if条件的外面，这样如果栈为空，就会出问题。 在try_reclaim()中(代码里面注解可以多看看，有助于理解)，首先如果检测到threads_in_pop为1，表示当前线程在执行完pop()中的while循环后仍然没有其他线程进入pop()，说明当前线程的old_head肯定只是被当前的线程所拥有，因此可以放心的删除(在此if分支的最下面)。此外，由于当前只有一个线程进入pop()，所以除了一定可以删除本线程的old_head外，还可以尝试删除待删除列表中的其他待删除节点，因为那些节点一定已经没有其他线程共享了。代码4处的处理逻辑非常的好，尤其要记住。因为是多线程，所以这里会先将待删除列表给移出来，这样如果发生线程切换，其他线程也在处理待删除列表，那么此处已经移出来的列表就不会对公共的待删除列表产生影响。一旦将待删除列表通过代码4处的方式移出来，当前线程就可以随意的处置这个待删除列表了，而不会对公共的待删除列表有任何影响(这个技巧很有用，以后还会遇到)。此处为啥代码5处还需要判断一下呢？因为在执行4之前，有可能其他线程将一个新的待删除节点存入到了待删除列表中，导致执行5时threads_in_pop不一定仍然为1(即使此时不为1了，仍然不影响当前线程的old_head，因为如果此时threads_in_pop不为1，说明当前线程已经执行完pop()中while循环后，其他线程才开始进入pop()函数的，那么当前线程的old_head节点仍然只被当前线程所拥有，因此仍然可以安全删除它)。也就是说当前待删除列表里面新进入的待删除节点有可能是被多个线程共享的。如果5处判断出threads_in_pop仍为1，表示刚刚分离出来的待删除列表中的所有待删除节点都不再被其他线程拥有，则可以将他们全部安全删除。如果此处判断threads_in_pop不再为1了，说明刚刚分离出来的待删除列表中有新的节点，因此这里不能直接删除，所以还得把这个待删除列表给接回到公共的待删除列表里面。最后我们看代码7处，如果一进来就发现threads_in_pop不为1，表明当前的old_head可能被其他线程共享，因此需要将当前线程的old_head节点加入的公共的待删除列表里面。 最后我们看看chain_pending_nodes()是如何将一个待删除列表加入到公共的待删除列表里的(单个节点属于容量为1的链表)。首先在代码8处找到已经分离出来的待删除列表的表头和表尾，然后通过代码9将公共待删除列表的表头接到分离出来的待删除列表的表尾，最后通过代码10，使用原子操作(这里就类似于pop()或push()函数中的对应操作，所以这些操作都是模式化的，非常有用)，将公共待删除列表的表头指向已经分离的待删除列表的表头，这样就把已经分离的待删除列表插入到了公共待删除列表的前面。 总结来说，这个方法就是将待删除节点先暂存起来，等到只有一个线程执行pop()时，再将这个待删除节点一起删除掉。 上面的代码在硬件负载不高的情况下效果不错。但是如果在高负载情况下，比如CPU使用率满了，且线程个数远大于CPU核心数，那么上述方法的效率就大打折扣。从上面代码可看出，只有当try_reclaim()中的代码5处的条件满足时，才能把公共待删除列表中的待删除节点给删除掉，如果此时有其他线程进入pop()，则就无法删除，很可能会导致公共待删除列表变得非常庞大。当负载很高时，有非常大的概率使得同时会有多个线程进入pop()，因而在高负载下有相当多的内存仍然无法及时释放。 其实上述方法还有一个潜在的问题，就是如果最后两个执行pop()的线程同时进入了try_reclaim()，并且它俩都发现threads_in_pop不为1，因此两个线程都会把各自的待删除节点加入到公共待删除列表里面。假如这两个线程执行完后，就再也没有其他线程来执行pop()了，那么公共待删除列表中的那些待删除节点就永远留在内存中而得不到释放，这也是一个巨大的问题。经过我在电脑上的实测，在高负载情况下很容易导致这种内存泄漏问题(特别是当多个线程pop的同时，还有其他线程在push的时候)，经常会检测到大量的待删除节点并未被删除，一直留到程序结束，从而导致大量内存占用。 2.6 使用 hazard-point 来管理内存释放问题hazard-point是一种技术，它的大概原理是：如果一个线程想访问一个可能会被其他线程给释放的内存对象，则此线程会首先将一个hazard-point指向这个对象，这样就会告诉其他线程，我正在使用这个对象，你要是此时删除这个对象的话，是很危险的(is hazardous)。一旦这个对象用完了，就清除hazard-point，这样，其他线程就可以愉快的删除这个对象了。 这个技术就是将一个对象的指针与当前线程的ID关联，然后将“指针-ID”对存储到一个公共区域，其他线程想要删除这个对象之前，需要去此公共区域查找这个对象有没有在公共区域与其他线程关联。 首先，需要准备一个所有线程可见的全局数组，数组的每个元素都会存储线程ID号以及一个对象的指针。当某个线程需要访问某个对象时，首先会把这个对象的地址和这个线程的ID存储到全局数组中。当另一个线程也访问相同的对象并尝试删除此对象时，会先去全局数组里面查找有没有其他线程存储这个对象的指针，如果有，则将待删除对象放到待删除列表中稍后删除，如果没有，则可以直接删除此对象。 我们先看看pop()函数中可能的实现： 12345678910111213141516171819202122232425262728293031323334std::shared_ptr&lt;T&gt; pop(){ std::atomic&lt;void*&gt;&amp; hp = get_hazard_pointer_for_current_thread(); // 1 node* old_head = head.load(); do // 2 { node* temp; do // 3 { temp = old_head; hp.store(old_head); old_head = head.load(); } while (old_head != temp); } while (old_head &amp;&amp; !head.compare_exchange_strong(old_head, old_head-&gt;next)); // 执行完上面的while循环后，hazard-point就不需要了，就可以删除了，因为old_head已经安全了 hp.store(nullptr); // 4 std::shared_ptr&lt;T&gt; res = nullptr; if (old_head) { res.swap(old_head-&gt;data); if (outstanding_hazard_pointers_for(old_head)) // 5 reclaim_later(old_head); else delete old_head; // 遍历其他节点，将那些已经没有被hazard-point引用的节点都删除 delete_nodes_with_no_hazards(); // 6 } return res;} 首先，通过代码1的函数得到数组hazard-point数组中的一个位置，且在获取的时候，就已经将当前线程ID存储到了hp对应的位置中。 关于此处的两个循环，先看外循环2， 2做的事情就是删除头节点，因为头节点可能会被其他线程改变，这里用了compare_exchange_strong。那么一旦别的线程修改了头节点，如果不重置hazard-point，那么当前hp存储的是以前旧的head，当前新的head被赋值给old_head后并没有加入到hazard-point数组中，导致其他线程可以对当前的head执行删除操作。所以循环3做的事情其实就是重置hp（当然包括以开始的初始化hp），使用循环的原因是在执行hp.store()的时候，栈的head已经被其他线程给修改了，导致此处的old_head已经与栈中的head不一致了。 另外，这里使用的是strong版本的原子操作，因为此while循环体中有大量的运算，所以为了避免weak版本因为伪失败而导致的多次循环，这里直接用strong版本的会有不错的性能提升。 之后到代码4处，因为已经执行过compare_exchange_strong()了，此处的old_head已经可以从hazard-point数组中移除了。这个时候的情况为，要么其他线程也拥有此old_head且也将其加入到了hazard-point数组中，要么其他线程没有引用此old_head，所以本线程可以安全将old_head移出hazard-point数组。 现在看代码5，此处的outstanding_hazard_pointers_for()函数是去全局hazard-point数组中查找有没有其他线程关联了这个old_head指针。其实由于在4处已经将本线程关联的old_head指针从hazard-point数组中删除了，因此此处只需要遍历hazard-point数组，查看有没有指针的值等于old_head就可以了，不需要对其线程ID做任何操作。 最后，代码6处的函数是为了删除待删除列表中那些已经不在hazard-point数组中的节点。其会遍历待删除列表的每个元素，然后通过outstanding_hazard_pointers_for()来判断元素是否在hazard-point数组中，如果不在，则直接删除，如果在，则继续遍历。 然后再看看如何实现hazard-point数组和待删除列表。书上为了将其通用化，也就是为了让hazard-point数组和待删除列表不仅可以用于此处，还可以用于其他数据结构，因此写的比较复杂，写成了模板。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124const unsigned max_hazard_points = 100;struct hazard_pointer{ std::atomic&lt;std::thread::id&gt; id; std::atomic&lt;void*&gt; pointer;};hazard_pointer hazard_pointers[max_hazard_points];class hp_owner{private: hazard_pointer* hp;public: hp_owner(const hp_owner&amp;) = delete; hp_owner&amp; operator=(const hp_owner&amp;) = delete; hp_owner() : hp(nullptr) { for (unsigned i = 0; i &lt; max_hazard_points; ++i) { std::thread::id old_id; if (hazard_pointers[i].id.compare_exchange_strong(old_id, std::this_thread::get_id())) { hp = &amp;hazard_pointers[i]; break; } } if (!hp) { throw std::runtime_error(&quot;No hazard pointers available&quot;); } } std::atomic&lt;void*&gt;&amp; get_pointer() { return hp-&gt;pointer; } ~hp_owner() { // 一定要注意释放的顺序，必须是先释放pointer，再释放id hp-&gt;pointer.store(nullptr); hp-&gt;id.store(std::thread::id()); }};std::atomic&lt;void*&gt;&amp; get_hazard_pointer_for_current_thread(){ // 在hazard初始化时就已经为这个线程分配了一个槽，然后此函数返回这个槽中的指针， // 外部通过对此指针赋值，将这个槽填充完整。 // 注意这里使用线程局部存储技术，使用static修饰，可以避免同一个线程中多次构造hp_owner对象 static thread_local hp_owner hazard; return hazard.get_pointer();}bool outstanding_hazard_pointers_for(void* p){ for (unsigned i = 0; i &lt; max_hazard_points; ++i) { if (hazard_pointers[i].pointer.load() == p) return true; } return false;}/********************* reclaim resources **********************//* 创建一个可重复使用的结构，用于存储待删除节点，并能够将不被hazard point引用的节点删除 */// 删除函数，用户可以自定义自己的删除函数template&lt;typename T&gt;void do_delete(void* p){ delete static_cast&lt;T*&gt;(p);}struct data_to_recliam{ void* data; std::function&lt;void(void*)&gt; deleter; // 用于删除节点的可调用对象 data_to_recliam* next; template&lt;typename T&gt; data_to_recliam(T* p) : data(p), deleter(&amp;do_delete&lt;T&gt;), next(nullptr) {} ~data_to_recliam() { // 通过析构函数来删除待删除的节点 deleter(data); }};std::atomic&lt;data_to_recliam*&gt; nodes_to_reclaim;void add_to_reclaim_list(data_to_recliam* node){ node-&gt;next = nodes_to_reclaim.load(); while (!nodes_to_reclaim.compare_exchange_weak(node-&gt;next, node));}template&lt;typename T&gt;void reclaim_later(T* data){ add_to_reclaim_list(new data_to_recliam(data));}void delete_nodes_with_no_hazards(){ // 从待删除链表里移出来，这样就可以肆无忌惮的处理这个链表了 data_to_recliam* current = nodes_to_reclaim.exchange(nullptr); while (current) { data_to_recliam* next = current-&gt;next; if (!outstanding_hazard_pointers_for(current-&gt;data)) delete current; // 将待删除链表本身的节点删除，然后其通过析构函数就能删除待删除的对象了 else add_to_reclaim_list(current); // 如果仍然有其他线程在引用这个待删除对象，则要重新加入到公共待删除链表里 current = next; }} 首先，创建一个结构体，用于将线程ID与一个指针关联。由于不知道指针指向的对象具体是什么类型，也不需要知道其是什么类型，因此指针使用void*。接着，定义一个全局数组，数组的大小一般来说是线程个数。然后，就创建一个管理hazard-point数组的类hp_owner，通过这个类的对象来管理hazard-point数组中指针的赋值以及线程ID的赋值，并通过析构函数来恢复hazard-point数组的元素，恢复为初始状态。注意到hp_owner的构造函数，当创建一个hp_owner对象时，就会从全局数组中找到一个未被使用的位置，并将当前线程ID存入进去，然后通过接口get_pointer()，可以在外部来设置对应的指针。另外要注意析构函数，这里的执行顺序不能反过来，否则有可能与构造函数中通过查找线程ID是否为空来赋值的情况相冲突。最后还要注意get_hazard_pointer_for_current_thread()函数中使用的是线程局部存储技术(thread_local)。这样，一个线程只需要一个hp_owner对象，线程中多次调用此函数都会对同一个hp_owner对象进行操作，而不同线程中hp_owner对象各不相同。 接下来我们看一下待删除列表的实现以及如何回收内存。首先，我们得把不能删除的数据存储到一个链表里面，链表的每个节点被定义为data_to_recliam类的对象。注意，此处有个用法，就是将模板放在了构造函数处，而不是类定义的开头处。这种用法挺好的，这样这个类在使用时就不需要传入模板参数了，而只需要在创建对象的时候加上模板参数就可以了(比如上述代码的所有data_to_recliam指针处都没有加模板参数)。注意，data_to_recliam里面还定义了一个删除器，可以指定删除数据的方式，这个特别好。当待删除列表的一个节点data_to_recliam被删除时，就会调用指定的删除器来删除对应的对象。最后看一下delete_nodes_with_no_hazards()接口，里面用到了上面用到过的技术，先把待删除列表从公共待删除列表里移出来，然后就可以随意处置了。如果某个节点不能删除，则再将那个节点给接回到公共到删除列表里面即可。 2.7 使用节点引用计数方法来实现内存安全回收2.7.1 使用智能指针来实现内存自动回收其实我们应该首先想到的就是使用智能指针shared_ptr&lt;&gt;技术了，当删除一个shared_ptr&lt;&gt;节点时，不需要去考虑内存释放问题，等无其他指针引用这个节点，它自己就会自动删除。不过，由于智能指针上的原子操作基本上都是有锁的，并不是lock-free的，因此性能会很低。如果在某种硬件平台上使得std::atomic_is_lock_free(&amp;some_shared_ptr)的返回值为true，那就完美了(即智能指针的原子操作都是无锁的)，既能够完美的解决内存回收的问题，效率也会非常高。我们看看使用智能指针技术的代码是什么样子的： 12345678910111213141516171819202122232425262728293031323334353637383940template&lt;typename T&gt;class lock_free_stack{private: struct node { std::shared_ptr&lt;T&gt; data; std::shared_ptr&lt;node&gt; next; node(const T&amp; data_) : data(std::make_shared&lt;T&gt;(data_)) {} };private: std::shared_ptr&lt;node&gt; head;public: void push(const T&amp; data) { std::shared_ptr&lt;node&gt; const new_node = std::make_shared&lt;node&gt;(data); new_node-&gt;next = std::atomic_load(&amp;head); while (!std::atomic_compare_exchange_weak(&amp;head, &amp;new_node-&gt;next, new_node)); } std::shared_ptr&lt;T&gt; pop() { std::shared_ptr&lt;node&gt; old_head = std::atomic_load(&amp;head); while (old_head &amp;&amp; !std::atomic_compare_exchange_weak(&amp;head, &amp;old_head, std::atomic_load(&amp;old_head-&gt;next))); // 1 这里使用了atomic_load if (old_head) { std::atomic_store(&amp;old_head-&gt;next, std::shared_ptr&lt;node&gt;(nullptr)); // 2 注意这行操作 return old_head-&gt;data; } return nullptr; } ~lock_free_stack() { while (pop()); }} 上面有两个注意点。首先，因为使用的是std::shared_ptr&lt;&gt;并且还要对其进行原子操作，因此，相关原子操作函数全部使用的是全局重载的原子操作函数。另外，在代码1处，注意这里的第三个实参是用的std::atomic_load()来获取next指针，这里不能直接传入next，必须使用std::atomic_load()转化一下。也就是说只要某个智能指针使用std::atomic_store()进行了存储，那么虽然存储的形式上仍然还是std::shared_ptr&lt;&gt;，但是如果你要真正使用其中的指针时，必须通过std::atomic_load()转回为正常的std::shared_ptr&lt;&gt;对象。 第二点是代码2，这里必须要把next指针给解除关联，不然极有可能会导致栈展开过深，导致程序崩溃。举个例子，比如线程a开始执行pop()，其将第一个节点取出并给了线程a的old_head，然而此时线程a挂起，然后线程b开始取出第二个节点并删除。但是由于第一个节点的next指针仍然指向第二个节点，所以第二个节点并不会真正的删除，只是将引用计数减去1。假如此时线程a仍然处于挂起状态，线程b又开始取出第三个节点并删除，但是由于第二个节点的next指针仍然指向第三个节点，所以第三个节点也不会被真正的删除…假如现在到了第1000个节点，线程b将第1000个节点取出，并删除，当然由前所述，第1000个节点也不会真正删除。此时，如果线程a切换回来了，开始执行，则线程a肯定会将第一个节点给删除。删除的时候，发现第一个节点的引用计数只有1，因此会将第一个节点给析构掉。析构前肯定会将类中的所有数据成员也析构掉，此时它发现对象中有一个next的智能指针对象，因此他肯定会先将next指针给析构掉，也就是会调用next对象的析构函数，也就是第二个节点对象的析构函数。然后它发现第二个节点对象也只有1个引用计数，因此第二个节点也会被析构，析构前也会将其中的next给析构掉…然后一直往下找。最终因为嵌套太深，导致栈展开太多，从而导致崩溃。 上述使用std::shared_ptr&lt;&gt;的方案效率非常低，效率可能比前两种方案要低10倍左右。不仅是pop()效率低，就连push()的效率也很低。 2.7.2 使用双引用计数法来实现高效的内存回收双引用计数法需要一个**外部计数器(external counter)和一个内部计数器(internal counter)**，这两个计数器的和就是引用当前这个节点的个数。外部计数器与指向节点的指针绑定在一起，每当读取一次节点的指针的时候，外部计数器就加1。当读取完成后，内部计数器就会减去1。也就是说，读取这个节点的指针的时候，外部计数器加1，读取完成后，内部计数器减1。当某个节点从stack中取出来后(此时这个节点在其他线程中可能被引用了，也可能没被引用)，此节点的内部计数器就等于此节点的外部计数器的值并减去1(internal_counter = external_counter - 1)。一旦内部计数器的值为0，就表示没有其他线程引用这个节点了，只有当前线程引用这个节点，因此当前线程就可以安全的回收这个节点的内存了。此外，一旦这个节点已经从stack中摘除，那么这个节点的外部计数器就不需要了，此时只需要内部计数器就行了。内部计数器用于当前线程或者其他线程来判断是否可以安全回收这个节点内存。我们来看一下最终的实现(这里书上给的是优化后的实现，其实比较难以理解，得多看看，注意多看代码里的注释)： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112template&lt;typename T&gt;class lock_free_stack{private: struct node; struct counted_node_ptr { // 注意，外部计数器用的是普通变量，因为外部计数器(或者说这个counted_node_ptr结构体对象) // 一般都是拷贝副本，并不会对单一对象执行并发访问 int external_count = 0; node* ptr = nullptr; }; struct node { std::shared_ptr&lt;T&gt; data; std::atomic&lt;int&gt; internal_count; // 内部计数器使用原子变量，因为内部计数器在节点内部，且这个点会被new出来，且被多个线程共享 counted_node_ptr next; // 注意，这里next并不是指针，而是一个结构体，一个包含外部计数器和下一个node指针的结构体，并不是指针 node(const T&amp; data_) : data(std::make_shared&lt;T&gt;(data_)), internal_count(0) {} };private: std::atomic&lt;counted_node_ptr&gt; head; // 注意，head此处不再是指针，而是结构体private: // 进入pop函数的第一件事就是将head的外部计数器递增，表示当前有一个线程打算读取node指针 void increase_head_count(counted_node_ptr&amp; old_counter) { counted_node_ptr new_counter; do { // 此循环是为了能够确保head能被此线程获取并将其外部节点递增 new_counter = old_counter; ++new_counter.external_count; } while (!head.compare_exchange_strong(old_counter, new_counter)); // 注意，这里不再是对比指针，而是通过二进制方式对比结构体对象是否相等 // 此处有可能发生线程切换，导致old_counter与当前真正的head不一致，不过没事，因为已经将之前的head的外部节点递增了，另一个线程可以负责处理那个head // 上面加了head.external_count，但并未增加old_counter.external_count，按理说old_counter是在描述head old_counter.external_count = new_counter.external_count; }public: void push(const T&amp; data) { counted_node_ptr new_node; // 这里并没有new出一个，直接创建一个栈对象 new_node.ptr = new node(data); // 真正的节点内容 new_node.external_count = 1; // 将外部节点初始化为1，因为当前有head在引用 new_node.ptr-&gt;next = head.load(); while (!head.compare_exchange_weak(new_node.ptr-&gt;next, new_node)); } std::shared_ptr&lt;T&gt; pop() { counted_node_ptr old_head = head.load(); // 先尝试获取当前head，不过，最终获取的以increase_head_count返回的为主 while (true) // 这里是一个大循环，没有退出条件，要么返回值，要么再次循环 { // 真正获取当前head，并将head的外部计数器递增1。注意，此时等此函数退出时，old_head并不一定等于当前stack的head increase_head_count(old_head); // 假如不在获取指针之前对外部计数器递增，则其他线程可能会释放这个ptr，导致当前线程的ptr变成了悬垂指针 node* const ptr = old_head.ptr; if (!ptr) { return nullptr; } // 这里的if才是真正尝试将head从stack中移除，如果发现当前的head与刚才获取的old_head不一致，说明当前线程在 // 获取old_head并将head的外部计数器递增1后，另一个线程将这个递增后的head给移除了，并没有轮到当前线程来处理。 if (head.compare_exchange_strong(old_head, ptr-&gt;next)) { // 如果发现head与old_head一致，那么就将head移除，然后将head更新为next。此时本线程就可以放心的处理old_head了。 // 注意，即使当前线程进入到了这里，old_head对应的指针可能也被其他线程的old_head对象所引用，这个就看old_head // 里的外部计数器的值了。 std::shared_ptr&lt;T&gt; res = nullptr; res.swap(ptr-&gt;data); // 注意，这里是用的swap，因为以后都肯定不会再访问这个data了，所以直接取出来就行，不用留着 // 如果其他线程并没有引用old_head中的node指针，则理论上old_head中的外部计数器的值是2，因为刚才在increase_head_count // 中对其进行了递增。如果此时其他线程也引用了old_head中对应的node指针，则此时old_head中的外部计数器的值一定大于2，且 // 减去2之后的值就是其他线程引用的个数(或者你可以这么理解，由于当前线程将不再引用这个节点，因此要把外部计数器减去1。然后 // 由于这个head节点已经从stack中移除了，所以stack不再引用这个节点了，因此外部引用计数又再次减去1)。然后就需要比较外部 // 计数器与内部计数器之和是否为0。如果之和为0，则表示现在没有其他线程引用这个节点了，那么就可以安全的删除这个节点了。 // 注意，如果它们之和为0，则表示internal_count之前的数值一定是-count_increase的值，因为fetch_add返回的是旧值，所以你 // 会发现下面比较有点怪异，不是比较0，而是比较旧值与-count_increase。 const int count_increase = old_head.external_count - 2; if (ptr-&gt;internal_count.fetch_add(count_increase) == -count_increase) { delete ptr; } return res; } else if (ptr-&gt;internal_count.fetch_sub(1) == 1) { // 不管是由于其他线程已经把这个节点的内容返回了，还是其他线程新加了节点到stack中，此时都要重新循环，从而重新得到新的head并pop。 // 但是在重新循环之前，由于上面在获取head时已经将head外部计数器加1了，那么这里需要将内部计数器减去1，表示当前线程不再引用这个节 // 点了。如果发现内部计数器减去1之后变成了0，则表示内部计数器之前是1，所以肯定有其他线程已经返回这个节点的内容了(只要确定内部 // 计数器的值大于0，就表示肯定有其他线程已经进入了上面的if分支并且会把节点中的值返回)，且如果正巧发现内部计数器的值为1，则表示 // 当前已经没有其他线程再引用这个节点了(因为当前线程马上就要将内部计数器减1，则内部计数器就变成了0，就表示没有任何线程拥有这个 // 节点了)。因此，此时就可以直接删除这个节点了。 // 前面返回的时候发现还有引用所以不回delete但是已经返回了，所以这里要delete，同时重新循环，直到成功返回。 delete ptr; } } } ~lock_free_stack() { while (pop()); }} 上述的双引用计数器方法不但能够解决内存回收的问题，而且效率非常的高，我自己测试后发现效率几乎和第一种方案一样高。不过，注意，这里效率高的前提是硬件平台支持双字节比较并交换操作，也就是当一个结构体的大小为双字节时，硬件对这个结构体执行比较并交换的原子操作是无锁的。如果你的硬件平台不支持双字节比较并交换操作，但是你知道你的引用计数的值是不超过某个范围的，是一个较小的数值，并且你得知你的硬件平台上指针中有额外的内存空间可用，那么你就可以使用单字节来同时存储指向node的指针ptr以及外部计数器external_counter(比如指针可能只需要用12个bit来存储就够了，那么剩下的4个bit就是空闲的，就可以用这4个bit来存储internal_counter的值)。这样，就可以使用单字节来实现此功能了，并且是无锁的。否则，上述这种实现由于counted_node_ptr结构体的原子操作并不是无锁的，其速度仍然很低，与使用内置指针的速度差不多(比如你在counted_node_ptr结构中多加一个无用的占位的成员变量，你就会发现上述这个实现并发执行速度仍然很低)。 3 没提过的基础知识——关于atomic &lt;T&gt;C++11给我们带来的Atomic一系列原子操作类，它们提供的方法能保证具有原子性。这些方法是不可再分的，获取这些变量的值时，永远获得修改前的值或修改后的值，不会获得修改过程中的中间数值。这些类都禁用了拷贝构造函数，原因是原子读和原子写是2个独立原子操作，无法保证2个独立的操作加在一起仍然保证原子性。 atomic&lt;T&gt;提供了常见且容易理解的方法： store：原子写操作 load：原子读操作 exchange：允许2个数值进行交换，并保证整个过程是原子的 compare_exchange_strong：即CAS，入参是3个，expect，desire，memoryorder，意思是如果当前的变量this的值==expect值，则将this值改为desire，并返回true，否则，将expect修改为this，返回false。 compare_exchange_weak：即CAS，和strong类似，但是这个函数可能在满足true的情况下仍然返回false，所以只能在循环里使用，否则可以使用它的strong版本。而这个weak版本考虑到了硬件性能的最优化，在使用CAS时一般都只会用到它。 大部分内容转载自[(56条消息) 高并发栈(stack)数据结构的无锁实现和超详细分析过程_zhjs_abc的博客-CSDN博客](https://blog.csdn.net/weixin_43376501/article/details/108325765#:~:text=实现无锁栈的基本结构 1 创建一个新的节点； 2,将新节点的next指针指向栈首 (head元素)； 3 将head指向新节点；) 参考： (56条消息) C++11 CAS无锁函数compare_exchange_weak的使用_chansoncc的博客-CSDN博客 (56条消息) C++11：原子交换函数compare_exchange_weak和compare_exchange_strong_原子变量exchange_吃素的施子的博客-CSDN博客 第7章 无锁并发数据结构设计 - 7.2 无锁数据结构的例子 - 《C++并发编程(中文版)（C++ Concurrency In Action）》 - 书栈网 · BookStack (56条消息) 【并发编程十五】无锁数据结构（1）——无锁栈_郑同学的笔记的博客-CSDN博客 [(56条消息) 高并发栈(stack)数据结构的无锁实现和超详细分析过程_zhjs_abc的博客-CSDN博客](https://blog.csdn.net/weixin_43376501/article/details/108325765#:~:text=实现无锁栈的基本结构 1 创建一个新的节点； 2,将新节点的next指针指向栈首 (head元素)； 3 将head指向新节点；)","link":"/2023/04/18/%E6%97%A0%E9%94%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88-C/"},{"title":"myMuduo回顾一：组件与整体逻辑","text":"1 前言先前仿照muduo网络库实现了myMuduo库，代码详见 MKMQ99/myMuduo: rewrite muduo (github.com) 这个库的特点是： 一个基于 reactor 反应堆模型的多线程 C++ 网络库，参考 muduo 网络库实现，去除了 boost 依赖 并发模型采用 one loop per thread + thread pool IO 复用采用的是 Epoll，LT 模式 这里再回顾一下库的实现。 2 一些基础类2.1 noncopyablenoncopyable 是一个公共基类，它的拷贝构造函数和赋值函数是delete的，被继承以后，派生类对象可以正常的构造和析构，但是派生类对象无法进行拷贝构造和赋值操作。 2.2 LoggerLogger类用于日志记录，使用单例模式构造，可设置日志级别为INFO、ERROR、FATAL、DEBUG。 Logger类： 123456789101112131415161718class Logger : noncopyable{ public: // 获取日志唯一的实例对象 static Logger* instance(); // 设置日志级别 void setLogLevel(int Level); // 写日志 void log(std::string msg); private: static Logger* log_; int LogLevel_; Logger(){}};Logger* Logger::instance(){ static Logger logger; return &amp;logger;} 2.3 TimeStamp看名字就知道用于时间戳 2.4 InetAddress封装socket地址类型，成员只有 sockaddr_in addr_ 一个，以及一系列成员函数，用于获得socket IP Port等信息 2.5 CurrentThread主要用于获取当前线程的线程id 3 事件分发类 ChannelChannel自始至终只负责一个fd的IO事件。每个Channel自始至终都属于一个EventLoop（一个EventLoop对应多个Channel，处理多个IO）。工作时，Channel类中保存这IO事件的类型以及对应的回调函数，当IO事件发生时，最终会调用到Channel类中的回调函数。 具体流程如下： 首先给定Channel所属的 loop，及其要处理的 fd，接着注册 fd 上需要监听的事件，可以调用接口函数enableReading或enableWriting来注册对应 fd 上的事件，disable* 是销毁指定的事件；然后通过 setCallback$来设置事件发生时的回调即可。 注册事件时函数调用关系，如下： Channel::update()-&gt;EventLoop::updateChannel(Channel)-&gt;Poller::updateChannel(Channel) 最终向 Epoll 系统调用的监听事件表注册或修改事件。 关于void Channel::tie(const std::shared_ptr&lt;void&gt; &amp;obj) 这里是一个智能指针使用的特定场景之一，用于延长特定对象的生命期 当对方断开TCP连接，这个IO事件会触发Channel::handleEvent()调用，后者会调用用户提供的CloseCallback，而用户代码在onClose()中有可能析构Channel对象，这就造成了灾难。等于说Channel::handleEvent()执行到一半的时候，其所属的Channel对象本身被销毁了。 所以采用void Channel::tie(const std::shared_ptr&lt;void&gt; &amp;obj)函数延长某些对象（可以是Channel对象，也可以是其owner对象）的生命期，使之长过Channel::handleEvent()函数。 Muduo TcpConnection采用shared_ptr管理对象生命期的原因之一就是因为这个。 当有关闭事件时，调用流程如下： Channel::handleEvent -&gt; TcpConnection::handleClose -&gt;TcpClient::removeConnection -&gt;TcpConnection::connectDestroyed-&gt;channel_-&gt;remove() 1、为了在Channel::handleEvent处理期间，防止因其owner对象被修改，进而导致Channel被析构，最后出现不可预估错误。 Channel::tie()的作用就是将Channel的owner对象进行绑定保护起来。 2、另外channel-&gt;remove的作用是删除channel在Poll中的地址拷贝，而不是销毁channel。channel的销毁由其owner对象决定。 4 IO multiplexing 类 Poller/EpollPollerPoller类负责监听文件描述符事件是否触发以及返回发生事件的文件描述符以及具体事件。 muduo提供了epoll和poll两种IO多路复用方法来实现事件监听。不过默认是使用epoll来实现，也可以通过选项选择poll。但是myMuduo库只支持epoll。 这个Poller是个抽象虚类，由EpollPoller继承实现，与监听文件描述符和返回监听结果的具体方法也基本上是在这两个派生类中实现。EpollPoller封装了用epoll方法实现的与事件监听有关的各种方法。 Poller/EpollPoller的重要成员变量： epollfd_就是用epoll_create方法返回的epoll句柄。 channels_：这个变量是std::unordered_map&lt;int, Channel*&gt;类型，负责记录 文件描述符 -&gt; Channel 的映射，也帮忙保管所有注册在你这个Poller上的Channel。 ownerLoop_：所属的EventLoop对象。 EpollPoller给外部提供的最重要的方法： 1TimeStamp poll(int timeoutMs, ChannelList *activeChannels) 这个函数可以说是Poller的核心了，当外部调用poll方法的时候，该方法底层其实是通过epoll_wait获取这个事件监听器上发生事件的fd及其对应发生的事件，我们知道每个fd都是由一个Channel封装的，通过哈希表channels_可以根据fd找到封装这个fd的Channel。将事件监听器监听到该fd发生的事件写进这个Channel中的revents成员变量中。然后把这个Channel装进activeChannels中（它是一个vector&lt;Channel*&gt;）。这样，当外界调用完poll之后就能拿到事件监听器的监听结果（activeChannels_），这个activeChannels就是事件监听器监听到的发生事件的fd，以及每个fd都发生了什么事件。 5 事件循环类 EventLoopEventLoop是负责事件循环的重要模块，Channel和Poller其实相当于EventLoop的手下，EventLoop整合封装了二者并向上提供了更方便的接口来使用。EventLoop和Channel，Poller的关系如下图： EventLoop最重要的函数就是事件循环函数void EventLoop::loop() 12345678910111213141516171819202122232425void EventLoop::loop(){ looping_ = true; quit_ = false; LOG_INFO(&quot;EventLoop %p start looping \\n&quot;, this); while(!quit_){ activeChannels_.clear(); // 监听两类fd 一种是client的fd 一种是wakeupFd pollReturnTime_ = poller_-&gt;poll(kPollTimeMs, &amp;activeChannels_); for (Channel *channel : activeChannels_){ // Poller监听哪些channel发生事件了，然后上报EventLoop，通知channel处理相应事件 channel-&gt;handleEvent(pollReturnTime_); } // 执行当前EventLoop事件循环需要处理的回调操作 /** * IO线程 mainLoop 接收连接，将 fd 打包给 channel，发给subLoop * mainLoop 事先注册一个回调cb（需要subLoop来执行） * wakeup subLoop后，执行下面的方法，执行maiinLoop注册的cb操作 */ doPendingFunctors(); } LOG_INFO(&quot;Eventloop %p stop looping \\n&quot;, this); looping_ = false;} 每一个EventLoop都绑定了一个线程（一对一绑定），也就是 one loop per thread 模型。 runInLoop()和queueInLoop()EventLoop有一个非常有用的功能：在它的IO线程内执行某个用户任务回调，即EventLoop::runInLoop(const Functor&amp; cb)，其中Functor是 boost::function。如果用户在当前IO线程调用这个函数，回调会 步进行；如果用户在其他线程调用runInLoop()，cb会被加入队列，IO 线程会被唤醒来调用这个Functor。 有了这个功能，我们就能轻易地在线程间调配任务，比方说把 TimerQueue的成员函数调用移到其IO线程，这样可以在不用锁的情况下 保证线程安全性。 wake()前面说到唤醒IO线程，EventLoop阻塞在poll函数上，怎么去唤醒它？以前的做法是利用pipe，向pipe中写一个字节，监视在这个pipe的读事件的poll函数就会立刻返回。在muduo中，采用了linux中eventfd调用。 每个EventLoop都有成员wakeupFd，以及相应封装的wakeupChannel。wakeupFd是每个EventLoop构造时生成的eventfd，EventLoop用这个wakeupFd构造一个Channel就是wakeupChannel，对这个Channel enableReading，并将其放入Poller，如果有别的线程想要唤醒这个EventLoop，只需要向wakeupFd对应的eventfd写入，Poller就会检测到可读事件，从而唤醒相应EventLoop。 doPendingFunctors()doPendingFunctors并没有直接在临界区去执行functors,而是利用了一个栈对象，把事件swap到栈对象中，再去执行。这样做有两个好处： 减少了临界区的长度，其它线程调用queueInLoop对pendingFunctors加锁时，就不会被阻塞 避免了死锁，可能在functors里面也会调用queueInLoop()，从而造成死锁。 回过头来看，muduo在处理多线程加锁访问共享数据的策略上，有一个很重要的原则:拼命减少临界区的长度。 6 EventLoop封装到线程中相关包括Thread类，EventLoopThread类，EventLoopThreadPool类 muduo的并发模型为one loop per thread+ threadpool。 EventLoopThread是事件循环线程，包含一个Thread对象，一个EventLoop对象。在构造函数中，把EventLoopThread::threadFunc 注册到Thread对象中（线程启动时会回调）。 EventLoopThread工作流程： 在主线程创建EventLoopThread对象。 主线程调用EventLoopThread.startLoop()，startLoop()调用EventLoopThread中的Thread成员thread_的start()方法，然后等待Loop创建完成。 thread_的start()方法会新创建一个线程，因为线程一创建直接启动，所以start()方法要等待线程创建完成再返回，这里使用的是信号量。 然后thread_调用回调函数回到EventLoopThread类的threadFunc()方法，创建新的Loop，创建完成使用条件变量通知startLoop()。 startLoop()返回新Loop。 EventLoopThreadPool是事件循环线程池，管理所有客户端连接，每个线程都有唯一一个事件循环，可以调用setThreadNum设置线程的数目。使用轮询策略获取事件循环线程。 总体逻辑： 7 Acceptor类Acceptor属于baseLoop或者说mainLoop，它负责处理新连接。Acceptor有成员acceptSocket（Socket对象）和acceptChannel（Channel对象），初始化一个Acceptor会创建一个socket和对应的Channel。当调用Acceptor的listen方法，acceptSocket开始listen，之后acceptChannel_.enableReading()。baseLoop检测到新连接就触发Acceptor的handleRead回调至TcpServer::newConnection，由TcpServer轮询找到subloop，根据连接成功的sockfd，创建TcpConnection连接对象，从而建立连接。 8 Buffer类应用层为什么需要Buffe：非阻塞IO的核心思想是避免阻塞在read()或write()或其它IO系统调用上，这样可以最大最大限度的复用。 TcpConnection需要有output buffer。假设程序想发送100KB的数据，但是调用write之后，操作系统只接受了80KB（受TCP advertised window控制），调用者肯定不想原地等待，如果有buffer，调用者只管将数据放入buffer，其它由网络库处理即可。 TcpConnection需要有input buffer。TCP是一个无边界的字节流协议，接收方必须要处理“收到的数据尚不构成一条完整的消息”和“一次收到两条消息的数据”等情况。如果有buffer，网络库收到数据之后，先放到input buffer，等构成一条完整的消息再通知程序的业务逻辑。同时，网络库在处理“socket 可读”事件的时候，必须一次性把 socket 里的数据读完（从操作系统 buffer 搬到应用层 buffer），否则会反复触发 POLLIN 事件，造成 busy-loop。 Buffer仅有3个成员，存放数据的vector&lt;char&gt; buffer_，已经size_t类型的readerIndex_和writerIndex_。 9 TcpConnection类这个类主要封装了一个已建立的TCP连接，以及控制该TCP连接的方法（连接建立和关闭和销毁），以及该连接发生的各种事件（读/写/错误/连接）对应的处理函数，以及这个TCP连接的服务端和客户端的套接字地址信息等。 TcpConnection类和Acceptor类可以认为是兄弟关系，Acceptor用于main EventLoop中，对服务器监听套接字fd及其相关方法进行封装（监听、接受连接、分发连接给SubEventLoop等），TcpConnection用于SubEventLoop中，对连接套接字fd及其相关方法进行封装（读消息事件、发送消息事件、连接关闭事件、错误事件等） TcpConnection的重要变量 socket_：用于保存已连接套接字文件描述符。 channel_：封装了上面的socket_及其各类事件的处理函数（读、写、错误、关闭等事件处理函数）。这个Channel种保存的各类事件的处理函数是在TcpConnection对象构造函数中注册的。 loop_：这是一个EventLoop*类型，该Tcp连接的Channel注册到了哪一个sub EventLoop上。这个loop_就是那一个sub EventLoop。 inputBuffer_：这是一个Buffer类，是该TCP连接对应的用户接收缓冲区。 outputBuffer_：也是一个Buffer类，不过是用于暂存那些暂时发送不出去的待发送数据。因为Tcp发送缓冲区是有大小限制的，假如达到了高水位线，就没办法把发送的数据通过send()直接拷贝到Tcp发送缓冲区，而是暂存在这个outputBuffer_中，等TCP发送缓冲区有空间了，触发可写事件了，再把outputBuffer_中的数据拷贝到Tcp发送缓冲区中。 state_：这个成员变量标识了当前TCP连接的状态（Connected、Connecting、Disconnecting、Disconnected） connetionCallback_、messageCallback_、writeCompleteCallback_、closeCallback_ ： 用户会自定义 [连接建立/关闭后的处理函数] 、[收到消息后的处理函数]、[消息发送完后的处理函数]以及Muduo库中定义的[连接关闭后的处理函数]。这四个函数都会分别注册给这四个成员变量保存。 10 最后配上总逻辑图 参考： (58条消息) Muduo 设计与实现之一：Buffer 类的设计_prependable_陈硕的博客-CSDN博客 万字长文梳理Muduo库核心代码及优秀编程细节思想剖析 - 知乎 (zhihu.com)","link":"/2023/04/22/myMuduo%E5%9B%9E%E9%A1%BE%E4%B8%80%EF%BC%9A%E7%BB%84%E4%BB%B6%E4%B8%8E%E6%95%B4%E4%BD%93%E9%80%BB%E8%BE%91/"},{"title":"myMuduo回顾二：其他部分","text":"1 epoll的具体使用1.1 创建epoll1234#include &lt;sys/epoll.h&gt;int epoll_create(int size);int epoll_create1(int flags); epoll_create() 可以创建一个epoll实例。在linux 内核版本大于2.6.8 后，这个size 参数就被弃用了，但是传入的值必须大于0。epoll_create() 会返回新的epoll对象的文件描述符。这个文件描述符用于后续的epoll操作。如果不需要使用这个描述符，请使用close关闭。 epoll_create1() 如果flags的值是0，epoll_create1()等同于epoll_create()。当然flags可以使用 EPOLL_CLOEXEC，和 open() 中的O_CLOEXEC 效果相同，主要是关闭子进程复制的父进程的文件描述符。 1.2 设置epoll事件123#include &lt;sys/epoll.h&gt;int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); 这个系统调用能够控制给定的文件描述符epfd指向的epoll实例，op是添加事件的类型，fd是目标文件描述符。 有效的op值有以下几种： EPOLL_CTL_ADD 在epfd中注册指定的fd文件描述符并指定fd相关的event。 EPOLL_CTL_MOD 改变fd相关联的event。 EPOLL_CTL_DEL 从指定的epfd中删除fd文件描述符。在这种模式中event是被忽略的，并且为可以等于NULL。 epoll_event的定义如下： 1234567891011typedef union epoll_data { void *ptr; int fd; uint32_t u32; uint64_t u64;} epoll_data_t;struct epoll_event { uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */}; 1.3 等待epoll事件123#include &lt;sys/epoll.h&gt;int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); epoll_wait等待文件描述符epfd引用的epoll实例上的事件。事件所指向的存储区域将包含可供调用者使用的事件。 epoll_wait最多返回maxevents个事件。maxevents参数必须大于零。timeout参数指定epoll_wait将阻塞的毫秒数，会一直阻塞到下面几种情况： 一个文件描述符触发了事件。 被一个信号处理函数打断，或者timeout超时。 指定超时值为-1会导致epoll_wait无限期阻塞，而指定的超时时间等于0导致epoll_wait立即返回，即使没有可用事件。 2 常见并发模型(58条消息) muduo库学习之详解muduo多线程模型（常见的并发网络服务器设计方案）_东阳z的博客-CSDN博客 3 Reactor和Proactor模型在网络IO设计中，有两种高性能模型：Reactor模型和Proactor模型。Reactor基于同步IO模式，Proactor基于异步IO模式。 3.1 Reactor 模型Reactor模型可以分为：单Reactor单线程、单Reactor多线程、主从Reactor多线程 Reactor模型的核心是：Reactor+Handles。Reactor在一个单独的线程中运行，负责监听和分发事件，将接收到的io事件交给不同的Handle来处理响应。Handles是处理程序执行I/O事件的实际操作，Reactor通过调度适当的Handles来处理io事件。 3.1.1 单Reactor单线程 流程： Reactor 对象通过 Select 监控客户端请求事件，收到事件后通过 Dispatch 进行分发。 如果是建立连接请求事件，则由 Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后的后续业务处理。 如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应 Handler 会完成 Read→业务处理→Send 的完整业务流程。 优点： 模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成。 缺点： 性能问题，只有一个线程，无法完全发挥多核 CPU 的性能。Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能阻塞。 可靠性问题，线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。 使用场景：客户端的数量有限，业务处理非常快速。java原生nio就是这个模型。 3.1.2 单Reactor多线程 流程： Reactor 对象通过select 监控客户端请求事件, 收到事件后，通过dispatch进行分发。 如果建立连接请求, 则由Acceptor 通过accept 处理连接请求, 然后创建一个Handler对象处理完成连接后的各种事件。 如果不是连接请求，则由reactor分发调用连接对应的handler 来处理。 handler 只负责响应事件，不做具体的业务处理, 通过read 读取数据后，会分发给后面的worker线程池的某个线程处理业务。 worker 线程池会分配独立线程完成真正的业务，并将结果返回给handler。 handler收到响应后，通过send 将结果返回给client。 优点： 可以充分的利用多核cpu 的处理能力。 缺点： 多线程数据共享和访问比较复杂， reactor 处理所有的事件的监听和响应，在单线程运行， 在高并发场景容易出现性能瓶颈.。 3.1.3 主从Reactor多线程 流程： Reactor主线程 MainReactor 对象通过select 监听连接事件, 收到事件后，通过Acceptor 处理连接事件。 当 Acceptor 处理连接事件后，MainReactor 将连接分配给SubReactor 。 subreactor 将连接加入到连接队列进行监听,并创建handler进行各种事件处理。 当有新事件发生时，subreactor 就会调用对应的handler处理。 handler 通过read 读取数据，分发给后面的worker 线程处理。 worker 线程池分配独立的worker 线程进行业务处理，并返回结果。 handler 收到响应的结果后，再通过send 将结果返回给client。 Reactor 主线程可以对应多个Reactor 子线程, 即MainRecator 可以关联多个SubReactor。 优点： 父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。 缺点： 编程复杂度较高。 应用场景：这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持。 3.2 Proactor模型Proactor 模式整体与Reactor 模式一致，区别就在于Proactor模式将所有I/O操作都交给主线程和内核来处理，工作线程仅仅负责业务逻辑。 这里需要注意的是： Proactor关注的不是就绪事件，而是完成事件，这是区分Reactor模式的关键点。 然而可惜的是，Linux下的异步 I/O 是不完善的，aio 系列函数是由 POSIX 定义的异步操作接口，不是真正的操作系统级别支持的，而是在用户空间模拟出来的异步，并且仅仅支持基于本地文件的 aio 异步操作，网络编程中的 socket 是不支持的，这也使得基于 Linux 的高性能网络程序都是使用 Reactor 方案。 优点 性能确实是强大，效率也高 缺点 复杂。性能好，效率高，东西是好东西，但是使用起来就是复杂。 操作系统支持。上面提到过，Linux系统对异步IO支持不是很好，不是很完善 3.3 两者的区别 Reactor 模式注册的是文件描述符的就绪事件。当Reactor 模式有事件发生时，它需要判断当前事件是读事件还是写事件，然后在调用系统的read或者write将数据从内核中拷贝到用户数据区，然后进行业务处理。 Proactor模式注册的则是完成事件。即发起异步操作后，操作系统将在内核态完成I/O并拷贝数据到用户提供的缓冲区中，完成后通知Proactor进行回调，用户只需要处理后续的业务即可。 Reactor模式实现同步I/O多路分发 Proactor模式实现异步I/O分发。 4 muduo的主线程accept的fd如何分发给其他线程？首先TcpServer初始化的时候会有一个mainLoop，Acceptor对应的Channel就是在mainLoop对应的Poller中注册事件的。一旦有了新连接，Poller就会上报EventLoop，通知channel处理相应事件。那么这里Channel回回调TcpServer::newConnection函数，再由它来分发给subLoop。再创建TcpConnection对应这个subLoop，subLoop去执行TcpConnection::connectEstablished()，在这函数里由对应的channel注册事件。 5 muduo定时器的实现在常见的定时函数中muduo选择timerfd实现定时器，原因如下： sleep / alarm / usleep在实现时有可能使用了SIGALRM信号，多线程程序中尽量避免使用信号，因为处理起来比较麻烦（信号通知进程，所有线程都将接收到这个信号，谁处理好）。另外，如果网络库定义了信号处理函数，用户代码(main函数等使用库的程序)也定义了信号处理函数，这不就冲突了，该调用哪个好。 nanosleep / clock_nanosleep是线程安全的，但是会让当前线程挂起等待一段时间，这会导致线程失去响应。在非阻塞网络编程中，绝对不能让线程挂起的方式来等待一段事件。正确的做法是注册一个事件回调函数。 gettimer和timer_create也是用信号来传递超时信息，在多线程中程序中也会有麻烦。 timerfd_create 把时间变成了一个文件描述符，该描述符在定时器超时的那一刻变为可读，可以很方便的融入到select/poll/epoll中，用同一的方式来处理IO事件和超时事件。 5.1 定时任务的原理 muduo采用timerfd_*将超时任务转换成文件描述符进行监听 当时间一到，timerfd变为可读，相应的Channel调用回调函数(TimerQueue::handleRead) 回调函数中将所有在TimerQueue中的超时任务找出，一次调用其回调函数 对于周期性定时任务，再添加回TimerQueue中 整个过程只有一个timerfd被Poller监听，所以调用timerfd_settime设置的超时时间一定是TimerQueue的set/map里最小的，即set.begin();第一个Timer任务。 而用户是通过调用EventLoop::runAt/runAfter/runEvery这些EventLoop的函数注册定时任务的，这些函数都需要向TimerQueue的set或者map中添加Timer，所以每添加一个都需要判断新添加的定时任务的超时时间是否小于设置的超时时间，如果小于，就需要调用timerfd_settime重新设置timerfd的超时时间。 而每次timerfd被激活都需要找到在set中所有的超时任务，因为有可能存在超时时间相等的定时任务，可以使用std::lower_bound函数找到第一个大于等于给定值的位置。 5.2 muduo定时器涉及的类muduo的定时器功能由三个类实现，TimerId、Timer、TimerQueue： Timer类是一个超时任务，保存超时时间，回调函数，以及记录自己是否是周期性计时任务，回调函数是用户提供的。 TimerId类用于保存超时任务Timer和它独一无二的id。 TimerQueue类保存用户设置的所有超时任务，需要高效保存尚未超时的任务，同时需要有序，方便找到超时时间最近的那个任务，可以用最小堆（libevent采用），也可以用std::set或者set::map存储（muduo采用）。 5.3 Timer类Timer封装了定时器的一些参数，例如超时回调函数、超时时间、定时器是否重复、重复间隔时间、定时器的序列号。其函数大都是设置这些参数，run()用来调用回调函数，restart()用来重启定时器（如果设置为重复）。其源码相对简单 12345678910111213141516171819202122232425262728293031class Timer : noncopyable {public: Timer(const TimerCallback &amp;cb, Timestamp when, double interval) : callback_(cb),//回调函数 expiration_(when),//超时时间 interval_(interval),//如果重复，间隔时间 repeat_(interval &gt; 0.0),//如果间隔大于0，就重复 sequence_(s_numCreated_.incrementAndGet()) {}//当前定时器的序列号 //调用回调函数. void run() const { callback_(); } Timestamp expiration() const { return expiration_; }//返回超时时刻 bool repeat() const { return repeat_; }//返回是否重复 int64_t sequence() const { return sequence_; }//返回定时器序号 void restart(Timestamp now);//重新开始 static int64_t numCreated() { return s_numCreated_.get(); }//返回最新的序号值private: const TimerCallback callback_; // 定时器回调函数 Timestamp expiration_; // 下一次的超时时间戳类 const double interval_; // 超时时间间隔，如果是一次性定时器，该值为0 const bool repeat_; // 是否重复 const int64_t sequence_; // 定时器序号，不会重复 static AtomicInt64 s_numCreated_; // 定时器计数，当前已经创建的定时器数量}; 5.4 TimerId类TimerId非常简单，它被设计用来取消Timer的，它的结构很简单，只有一个Timer指针和其序列号。 12345678910111213141516171819class TimerId {public: TimerId() : timer_(NULL), sequence_(0) { } TimerId(Timer *timer, int64_t seq) : timer_(timer), sequence_(seq) { } friend class TimerQueue;//友元，就是可以访问类的私有成员变量，但不是类中的成员private: Timer *timer_; int64_t sequence_;}; 5.5 TimerQueue类虽然TimerQueue中有Queue，但是其实现时基于Set的，而不是Queue。这样可以高效地插入、删除定时器，且找到当前已经超时的定时器。TimerQueue的public接口只有两个，添加和删除。 123// 一定是线程安全的，可以跨线程调用。通常情况下被其它线程调用void addTimerInLoop(Timer* timer);void cancelInLoop(TimerId timerId); 类定义的源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class TimerQueue : noncopyable{public: explicit TimerQueue(EventLoop* loop); ~TimerQueue(); // 添加定时器接口，函数返回定时器唯一ID TimerId addTimer(TimerCallback cb, //回调函数 Timestamp when, //超时时间 double interval); //时间间隔 // 取消定时器，通过addTimer()返回的定时器唯一ID void cancel(TimerId timerId);private: // 定时器容器的相关数据结构 typedef std::pair&lt;Timestamp, Timer*&gt; Entry; typedef std::set&lt;Entry&gt; TimerList; // 用于记录活跃定时器和取消定时器容器的相关数据结构 typedef std::pair&lt;Timer*, int64_t&gt; ActiveTimer; typedef std::set&lt;ActiveTimer&gt; ActiveTimerSet; // 由EventLoop::runInLoop()触发添加定时器 void addTimerInLoop(Timer* timer); // 由EventLoop::runInLoop()触发取消定时器 void cancelInLoop(TimerId timerId); // 定时器超时的处理函数 void handleRead(); // 从定时器列表中找到所有到期的定时器 std::vector&lt;Entry&gt; getExpired(Timestamp now); // 将重复的超时定时器重新添加到定时器列表timers_中 void reset(const std::vector&lt;Entry&gt;&amp; expired, Timestamp now); // 添加定时器到容器 bool insert(Timer* timer); EventLoop* loop_; //所属的事件循环 const int timerfd_; //timerfd_create()创建的文件描述符 Channel timerfdChannel_; //用于监听timerfd的Channel TimerList timers_; //定时器列表 // 用于取消定时器，通过唯一ID找到对应的定时器 ActiveTimerSet activeTimers_; //活跃定时器记录 bool callingExpiredTimers_; ActiveTimerSet cancelingTimers_; //取消定时器记录}; 首先，看下TimerQueue提供的添加定时器的接口函数addTimer()： 1234567891011TimerId TimerQueue::addTimer(TimerCallback cb, Timestamp when, double interval){ // 创建定时器类 Timer* timer = new Timer(std::move(cb), when, interval); loop_-&gt;runInLoop( std::bind(&amp;TimerQueue::addTimerInLoop, this, timer)); // 返回定时器唯一ID return TimerId(timer, timer-&gt;sequence());} addTimer()通过所属的事件循环调用EventLoop::runInLoop()触发添加定时器函数TimerQueue::addTimerInLoop()。 1234567891011void TimerQueue::addTimerInLoop(Timer* timer){ loop_-&gt;assertInLoopThread(); bool earliestChanged = insert(timer); //判断是否需要更新 timerfd 的超时时间 if (earliestChanged) { resetTimerfd(timerfd_, timer-&gt;expiration()); }} addTimerInLoop()实际就是调用了TimerQueue::insert()来添加定时器到容器中。如果定时器容器为空或者新添加的定时器位于容器的顶部，即超时时间比当前小，就通过resetTimerfd()(timerfd_settime()的封装)来更新超时时间。 insert()源码如下： 123456789101112131415161718192021222324252627bool TimerQueue::insert(Timer* timer){ loop_-&gt;assertInLoopThread(); assert(timers_.size() == activeTimers_.size()); bool earliestChanged = false; Timestamp when = timer-&gt;expiration(); TimerList::iterator it = timers_.begin(); if (it == timers_.end() || when &lt; it-&gt;first) //定时器容器为空 或 超时时间比当前小 { earliestChanged = true; } { // 添加到定时器列表 timers_ 中 std::pair&lt;TimerList::iterator, bool&gt; result = timers_.insert(Entry(when, timer)); assert(result.second); (void)result; } { // 添加到活跃定时器列表 activeTimers_ 中，用于取消定时器是查找 std::pair&lt;ActiveTimerSet::iterator, bool&gt; result = activeTimers_.insert(ActiveTimer(timer, timer-&gt;sequence())); assert(result.second); (void)result; } assert(timers_.size() == activeTimers_.size()); return earliestChanged;} 定时器添加的流程就是：addTimer()=&gt;EventLoop::runInLoop()=&gt;addTimerInLoop()=&gt;insert()。但是使用时，并不直接调用addTimer()，EventLoop对其做了更加完善的封装，提供给用户，接口如下： 123TimerId EventLoop::runAt(Timestamp time, TimerCallback cb) { /... }TimerId EventLoop::runAfter(double delay, TimerCallback cb) { /... }TimerId EventLoop::runEvery(double interval, TimerCallback cb) { /... } 当timerfd超时，调用定时器超时的处理函数TimerQueue::handleRead()，此函数在容器构造时通过Channel注册，源码如下： 1234567891011TimerQueue::TimerQueue(EventLoop* loop) : loop_(loop), timerfd_(createTimerfd()), timerfdChannel_(loop, timerfd_), timers_(), callingExpiredTimers_(false){ timerfdChannel_.setReadCallback( std::bind(&amp;TimerQueue::handleRead, this)); timerfdChannel_.enableReading();} handleRead()通过TimerQueue::getExpired()从定时器列表中找到所有到期的定时器，然后依次执行其回调函数，并将重复的超时定时器重新添加到定时器列表timers_中，源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475void TimerQueue::handleRead(){ loop_-&gt;assertInLoopThread(); Timestamp now(Timestamp::now()); readTimerfd(timerfd_, now); // 从定时器列表中找到所有到期的定时器 std::vector&lt;Entry&gt; expired = getExpired(now); callingExpiredTimers_ = true; cancelingTimers_.clear(); for (const Entry&amp; it : expired) { it.second-&gt;run(); //依次执行其回调函数 } callingExpiredTimers_ = false; // 将重复的超时定时器重新添加到定时器列表 timers_ 中 reset(expired, now);}std::vector&lt;TimerQueue::Entry&gt; TimerQueue::getExpired(Timestamp now){ assert(timers_.size() == activeTimers_.size()); std::vector&lt;Entry&gt; expired; Entry sentry(now, reinterpret_cast&lt;Timer*&gt;(UINTPTR_MAX)); // 利用 lower_bound() 找到第一个大于等于参数的位置，返回迭代器 TimerList::iterator end = timers_.lower_bound(sentry); assert(end == timers_.end() || now &lt; end-&gt;first); // 构造vector&lt;Entry&gt; std::copy(timers_.begin(), end, back_inserter(expired)); timers_.erase(timers_.begin(), end); for (const Entry&amp; it : expired) { ActiveTimer timer(it.second, it.second-&gt;sequence()); size_t n = activeTimers_.erase(timer); assert(n == 1); (void)n; } assert(timers_.size() == activeTimers_.size()); return expired;}void TimerQueue::reset(const std::vector&lt;Entry&gt;&amp; expired, Timestamp now){ Timestamp nextExpire; for (const Entry&amp; it : expired) { ActiveTimer timer(it.second, it.second-&gt;sequence()); if (it.second-&gt;repeat() //判断是否时重复定时器 &amp;&amp; cancelingTimers_.find(timer) == cancelingTimers_.end()) //判断用户是否取消了这个定时任务 { it.second-&gt;restart(now); //重新计算超时时间 insert(it.second); //重新添加到容器中 } else { delete it.second; } } // 计算下次timerfd被激活的时间 if (!timers_.empty()) { nextExpire = timers_.begin()-&gt;second-&gt;expiration(); } // 设置超时时间 if (nextExpire.valid()) { resetTimerfd(timerfd_, nextExpire); }} 6 多线程情况下如何做到线程安全的对象生命期管理6.1 对象构造对象构造要做到线程安全，唯一的要求是在构造期间不要泄露 this 指针 不要在构造函数中注册任何回调 也不要在构造函数中把 this 传给跨线程的对象 6.2 连接更新、析构等操作什么是线程安全：所谓线程安全是指凡是非共享的对象都是彼此独立的，如果一个对象从始至终只被一个线程用到，那么它就是安全的。共享的对象的read-only操作是安全的，前提是不能有并发的写操作。（如果有并发的写操作那么将会是线程不安全的），同样在多线程C++中还要注意多个线程如果都可以访问一个对象时的对象析构问题，所以对于这样的对象最好采取智能指针去管理。所以说在并发服务器里，对于同一个连接是不能够供多个线程同时进行读或者写，所以muduo库规定所有的读写操作只能在IO线程（包括连接关闭操作）中来完成。muduo库通过runInLoop和queueInLoop这两个函数来保证将可能在其他线程执行的IO操作放入到IO线程来完成。（比如在线程池中的线程可能会用到send操作或者close操作） muduo规定的必须在IO线程完成的操作：连接的更新、连接的读写、连接的关闭、连接的析构等 一些置于所属线程的例子： TcpServer::start():将Acceptor::listen置于所属线程： 一直不理解为什么这里需要将listen放到其所属线程中（因为listen的描述符一定是在IO线程中的）可能原因是其他从reactor线程中可能会创建监听描述符。 TcpServer::newConnection():将TcpConnection::connectEstablished置于所属线程 这是肯定的，因为connectEstablished函数涉及连接的更新操作，这个函数应该由其连接所属的线程来调用，而此时的函数是监听fd所属的线程所以需要采取此操作。 TcpServer::removeConnection:将removeConnectionInLoop置于所属线程 为了避免在删除map中的conn对象时出现竞争，muduo规定只能在map（也就是监听fd）所属的线程中进行删除操作，从而避免了多个线程使用map而造成的竞争。 TcpServer::removeConnectionInLoop:将TcpConnection::connectDestroyed置于queueInLoop 此操作根本是保证channel不会在TcpConnection对象析构后而析构，因为handleRead等操作是由channel直接调用的，但是此函数可能会直接将channel析构调用从而出现段错误，所以采用此操作使得channel的析构推迟。 TcpConnection::send:将TcpConnection::sendInLoop置于所属线程 因为线程池的线程可能会采用send操作 TcpConnection::shutdown将TcpConnection::shutdownInLoop置于所属线程 因为线程池中的线程可能会采用shutdown操作 TcpServer::~TcpServer将TcpConnection::connectionDestroy置于所属线程 因为TcpServer在析构时需要关闭所有的连接，而析构函数是在监听fd所属的IO线程的，所有要采取此操作。 TcpConnection::forceClose将TcpConnection::forceCloseInLoop置于所属线程 因为线程池中的线程可能会采用forceClose操作 7 muduo如何限制连接的数量？服务器的文件描述符数量有限，因此需要一些手段来限制服务器的最大并发连接数。需要这么做的原因是：某个时刻服务器文件描述符已经用完了，此时再来一个连接，将无法用描述符表示这个连接，也就无法关闭这个连接。在Reactor模式下，POLLIN事件就会一直被触发（level trigger模式），就会进入busy loop，cpu 利用率将到达100%。 因此有必要设计一个策略，当服务器并发数目到达上限时，主动的拒接连接。muduo使用的办法很巧妙（？？？）： 1.准备一个空闲的描述符2.当遇到上述情况时，先close掉这个空闲的文件描述符，这样就多出一个可用描述符3.接收新的连接后就有文件描述符来表示这个连接了。4.此时close掉这个描述符，就关掉了客户端连接5.再次打开这个空闲的描述符。 并未在代码中找到上述策略，真实代码中貌似仅仅是在大于最大连接数时将连接shutdown了。 8 muduo为什么用LT模式 为了与传统的poll(2)兼容，因为在文件描述符数目较少， 活动文件描述符比例较高时，epoll(4)不见得比poll(2)更高效，必要时可以在进程启动时切换Poller。 level trigger编程更容易，以往 select(2)/poll(2)的经验都可以继续用，不可能发生漏掉事件的bug。 读写的时候不必等候出现EAGAIN，可以节省系统调用次数，降低延迟。 9 LT模式和ET模式剖析Level Triggered (LT) 水平触发 socket接收缓冲区不为空，有数据可读，读事件一直触发 socket发送缓冲区不满，可以继续写入数据，写事件一直触发 符合思维习惯，epoll_wait返回的事件就是socket的状态 Edge Triggered (ET) 边沿触发 socket的接收缓冲区状态变化时触发读事件，即空的接收缓冲区刚接收到数据时触发读事件 socket的发送缓冲区状态变化时触发写事件，即满的缓冲区刚空出空间时触发读事件 仅在状态变化时触发事件 LT的处理过程： accept一个连接，添加到epoll中监听EPOLLIN事件 当EPOLLIN事件到达时，read fd中的数据并处理 当需要写出数据时，把数据write到fd中；如果数据较大，无法一次性写出，那么在epoll中监听EPOLLOUT事件 当EPOLLOUT事件到达时，继续把数据write到fd中；如果数据写出完毕，那么在epoll中关闭EPOLLOUT事件 ET的处理过程： accept一个一个连接，添加到epoll中监听EPOLLIN|EPOLLOUT事件 当EPOLLIN事件到达时，read fd中的数据并处理，read需要一直读，直到返回EAGAIN为止 当需要写出数据时，把数据write到fd中，直到数据全部写完，或者write返回EAGAIN 当EPOLLOUT事件到达时，继续把数据write到fd中，直到数据全部写完，或者write返回EAGAIN 从ET的处理过程中可以看到，ET的要求是需要一直读写，直到返回EAGAIN，否则就会遗漏事件。而LT的处理过程中，直到返回EAGAIN不是硬性要求，但通常的处理过程都会读写直到返回EAGAIN，但LT比ET多了一个开关EPOLLOUT事件的步骤。 LT的编程与poll/select接近，符合一直以来的习惯，不易出错ET的编程可以做到更加简洁，某些场景下更加高效，但另一方面容易遗漏事件，容易产生bug 10 什么情况下用ET模式在eventloop类型(包括各类fiber/coroutine)的程序中, 处理逻辑和epoll_wait都在一个线程, ET相比LT没有太大的差别。反而由于LT醒的更频繁, 可能时效性更好些。但在更高并发的RPC实现中, 为了对大消息的反序列化也可以并行, 消息的读取和分割可能运行和epoll_wait不同的线程中, 这时ET是必须的, 否则在读完数据前, epoll_wait会不停地无谓醒来。 11 如果内核写缓冲区充足，epoll的LT模式会反复的触发可写事件，怎么解决先不关注可写事件，有数据写直接往socket写，如果没写完，把没写完的数据放到应用层缓冲区，然后关注可写事件。 参考： 详解Reactor模型 - 清烟无瘾 - 博客园 (cnblogs.com) 【死磕 NIO】— Proactor模式是什么？很牛逼吗？ - 知乎 (zhihu.com) (58条消息) muduo net库学习笔记3——定时器的实现_听说西佳佳难得很的博客-CSDN博客 muduo源码学习(三) 定时器实现 - 简书 (jianshu.com) muduo源码分析之定时器TimerQueue - Fitz~ - 博客园 (cnblogs.com) (58条消息) muduo库学习笔记-线程安全_张火油的博客-CSDN博客 (58条消息) epoll LT/ET 深入剖析_dongfuye的博客-CSDN博客","link":"/2023/04/22/myMuduo%E5%9B%9E%E9%A1%BE%E4%BA%8C%EF%BC%9A%E5%85%B6%E4%BB%96%E9%83%A8%E5%88%86/"},{"title":"CMake学习","text":"1 什么是CMake？CMake是一个跨平台的编译(Build)工具,可以用简单的语句来描述所有平台的编译过程。简单来说，CMake可以跨平台生成对应平台能用的makefile。 2 CMake一个HelloWorld 写一个HelloWorld 123456#include &lt;iostream&gt;int main(){ std::cout &lt;&lt; &quot;HelloWorld!&quot; &lt;&lt; std::endl; return 0;} 写CMakeLists.txt 123456789PROJECT (HELLO)SET(SRC_LIST main.cpp)MESSAGE(STATUS &quot;This is BINARY dir &quot; ${HELLO_BINARY_DIR})MESSAGE(STATUS &quot;This is SOURCE dir &quot;${HELLO_SOURCE_DIR})ADD_EXECUTABLE(hello ${SRC_LIST}) 使用cmake，生成makefile文件 1234567891011121314151617181920212223242526sq@ubuntu:~/Desktop/cmake_study/cmake01$ cmake .CMake Warning (dev) at CMakeLists.txt:7: Syntax Warning in cmake code at column 37 Argument not separated from preceding token by whitespace.This warning is for project developers. Use -Wno-dev to suppress it.-- The C compiler identification is GNU 9.4.0-- The CXX compiler identification is GNU 9.4.0-- Check for working C compiler: /usr/bin/cc-- Check for working C compiler: /usr/bin/cc -- works-- Detecting C compiler ABI info-- Detecting C compiler ABI info - done-- Detecting C compile features-- Detecting C compile features - done-- Check for working CXX compiler: /usr/bin/c++-- Check for working CXX compiler: /usr/bin/c++ -- works-- Detecting CXX compiler ABI info-- Detecting CXX compiler ABI info - done-- Detecting CXX compile features-- Detecting CXX compile features - done-- This is BINARY dir /home/sq/Desktop/cmake_study/cmake01-- This is SOURCE dir /home/sq/Desktop/cmake_study/cmake01-- Configuring done-- Generating done-- Build files have been written to: /home/sq/Desktop/cmake_study/cmake01 目录下就生成了这些文件：CMakeFiles, CMakeCache.txt, cmake_install.cmake 等文件，并且生成了Makefile。 使用make命令编译 12345sq@ubuntu:~/Desktop/cmake_study/cmake01$ makeScanning dependencies of target hello[ 50%] Building CXX object CMakeFiles/hello.dir/main.cpp.o[100%] Linking CXX executable hello[100%] Built target hello 最终生成了Hello的可执行程序 3 CMake一个HelloWord的语法介绍3.1 PROJECT关键字可以用来指定工程的名字和支持的语言，默认支持所有语言 PROJECT (HELLO) 指定了工程的名字，并且支持所有语言—建议 PROJECT (HELLO CXX) 指定了工程的名字，并且支持语言是C++ PROJECT (HELLO C CXX) 指定了工程的名字，并且支持语言是C和C++ 该指定隐式定义了两个CMAKE的变量 &lt;projectname&gt;_BINARY_DIR，本例中是 HELLO_BINARY_DIR &lt;projectname&gt;_SOURCE_DIR，本例中是 HELLO_SOURCE_DIR MESSAGE关键字就可以直接使用者两个变量，当前都指向当前的工作目录，后面会讲外部编译 问题：如果改了工程名，这两个变量名也会改变 解决：又定义两个预定义变量：PROJECT_BINARY_DIR和PROJECT_SOURCE_DIR，这两个变量和HELLO_BINARY_DIR，HELLO_SOURCE_DIR是一致的。所以改了工程名也没有关系 3.2 SET关键字用来显示的指定变量的 SET(SRC_LIST main.cpp) SRC_LIST变量就包含了main.cpp 也可以 SET(SRC_LIST main.cpp t1.cpp t2.cpp) 3.3 MESSAGE关键字向终端输出用户自定义的信息 主要包含三种信息： SEND_ERROR，产生错误，生成过程被跳过。 SATUS，输出前缀为 “–” 的信息。 FATAL_ERROR，立即终止所有 cmake 过程. 3.4 ADD_EXECUTABLE关键字生成可执行文件 ADD_EXECUTABLE(hello ${SRC_LIST}) 生成的可执行文件名是hello，源文件读取变量SRC_LIST中的内容 也可以直接写 ADD_EXECUTABLE(hello main.cpp) 上述例子可以简化的写成 PROJECT(HELLO)ADD_EXECUTABLE(hello main.cpp) 注意：工程名的 HELLO 和生成的可执行文件 hello 是没有任何关系的 4 语法的基本原则 变量使用${}方式取值，但是在 IF 控制语句中是直接使用变量名 指令(参数 1 参数 2…) 参数使用括弧括起，参数之间使用空格或分号分开。 以上面的 ADD_EXECUTABLE 指令为例，如果存在另外一个 func.cpp 源文件 就要写成：ADD_EXECUTABLE(hello main.cpp func.cpp)或者ADD_EXECUTABLE(hello main.cpp;func.cpp) 指令是大小写无关的，参数和变量是大小写相关的。但，推荐你全部使用大写指令 语法注意事项 SET(SRC_LIST main.cpp) 可以写成 SET(SRC_LIST “main.cpp”)，如果源文件名中含有空格，就必须要加双引号 ADD_EXECUTABLE(hello main) 后缀可以不行，他会自动去找.c和.cpp，最好不要这样写，可能会有这两个文件main.cpp和main 5 内部构建和外部构建 上述例子就是内部构建，他生产的临时文件特别多，不方便清理 外部构建，就会把生成的临时文件放在build目录下，不会对源文件有任何影响强烈使用外部构建方式 外部构建方式举例 建立一个build目录，可以在任何地方，建议在当前目录下 进入build，运行cmake .. 当然..表示上一级目录，你可以写CMakeLists.txt所在的绝对路径，生产的文件都在build目录下了 在build目录下，运行make来构建工程 注意外部构建的两个变量 1、HELLO_SOURCE_DIR 还是工程路径，也就是 /home/sq/Desktop/cmake_study/cmake01 2、HELLO_BINARY_DIR 编译路径，也就是 /home/sq/Desktop/cmake_study/cmake01/build 6 让HelloWorld看起来更像一个工程 为工程添加一个子目录 src，用来放置工程源代码 添加一个子目录 doc，用来放置这个工程的文档 hello.txt 在工程目录添加文本文件 COPYRIGHT, README 在工程目录添加一个 runhello.sh 脚本，用来调用 hello 二进制 将构建后的目标文件放入构建目录的 bin 子目录 将 doc 目录的内容以及 COPYRIGHT/README 安装到/usr/share/doc/cmake/ 6.1 将目标文件放入构建目录的 bin 子目录每个目录下都要有一个CMakeLists.txt说明 1234567[root@localhost cmake]# tree.├── build├── CMakeLists.txt└── src ├── CMakeLists.txt └── main.cpp 外层CMakeLists.txt 12PROJECT(HELLO)ADD_SUBDIRECTORY(src bin) src下的CMakeLists.txt 1ADD_EXECUTABLE(hello main.cpp) 6.1.1 ADD_SUBDIRECTORY 指令ADD_SUBDIRECTORY(source_dir [binary_dir] [EXCLUDE_FROM_ALL]) 这个指令用于向当前工程添加存放源文件的子目录，并可以指定中间二进制和目标二进制存放的位置 EXCLUDE_FROM_ALL函数是将写的目录从编译中排除，如程序中的example ADD_SUBDIRECTORY(src bin) 将 src 子目录加入工程并指定编译输出(包含编译中间结果)路径为bin 目录 如果不进行 bin 目录的指定，那么编译结果(包括中间结果)都将存放在build/src 目录 6.1.2 更改二进制的保存路径SET 指令重新定义 EXECUTABLE_OUTPUT_PATH 和 LIBRARY_OUTPUT_PATH 变量来指定最终的目标二进制的位置 SET(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin)SET(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib) 思考：加载哪个CMakeLists.txt当中 哪里要改变目标存放路径，就在哪里加入上述的定义，所以应该在src下的CMakeLists.txt下写 7 安装 一种是从代码编译后直接 make install 安装 一种是打包时的指定目录安装。 简单的可以这样指定目录：make install DESTDIR=/tmp/test 稍微复杂一点可以这样指定目录：./configure –prefix=/usr 7.1 如何安装HelloWord使用CMAKE一个新的指令：INSTALL INSTALL的安装可以包括：二进制、动态库、静态库以及文件、目录、脚本等 使用CMAKE一个新的变量：CMAKE_INSTALL_PREFIX 123456789101112131415// 目录树结构[root@localhost cmake]# tree.├── build├── CMakeLists.txt├── COPYRIGHT├── doc│ └── hello.txt├── README├── runhello.sh└── src ├── CMakeLists.txt └── main.cpp3 directories, 7 files 7.2 安装文件COPYRIGHT和READMEINSTALL(FILES COPYRIGHT README DESTINATION share/doc/cmake/) FILES：文件 DESTINATION： 写绝对路径 可以写相对路径，相对路径实际路径是：${CMAKE_INSTALL_PREFIX}/&lt;DESTINATION 定义的路径&gt; ​ CMAKE_INSTALL_PREFIX 默认是在 /usr/local/ ​ cmake -DCMAKE_INSTALL_PREFIX=/usr 在cmake的时候指定CMAKE_INSTALL_PREFIX变量的路径 7.3 安装脚本runhello.shPROGRAMS：非目标文件的可执行程序安装(比如脚本之类) INSTALL(PROGRAMS runhello.sh DESTINATION bin) 说明：实际安装到的是 /usr/bin 7.4 安装 doc 中的 hello.txt 一、是通过在 doc 目录建立CMakeLists.txt ，通过install下的file 二、是直接在工程目录通过 INSTALL(DIRECTORY doc/ DESTINATION share/doc/cmake) DIRECTORY 后面连接的是所在 Source 目录的相对路径 注意：abc 和 abc/有很大的区别 目录名不以/结尾：这个目录将被安装为目标路径下的 目录名以/结尾：将这个目录中的内容安装到目标路径 7.5 安装过程cmake .. make make install 8 静态库和动态库的构建任务： 建立一个静态库和动态库，提供 HelloFunc 函数供其他程序编程使用，HelloFunc 向终端输出 Hello World 字符串。 安装头文件与共享库。 静态库和动态库的区别 静态库的扩展名一般为“.a”或“.lib”；动态库的扩展名一般为“.so”或“.dll”。 静态库在编译时会直接整合到目标程序中，编译成功的可执行文件可独立运行 动态库在编译时不会放到连接的目标程序中，即可执行文件无法单独运行。 8.1 构建实例12345678[root@localhost cmake2]# tree.├── build├── CMakeLists.txt└── lib ├── CMakeLists.txt ├── hello.cpp └── hello.h hello.h中的内容 123456#ifndef HELLO_H#define Hello_Hvoid HelloFunc();#endif hello.cpp中的内容 12345#include &quot;hello.h&quot;#include &lt;iostream&gt;void HelloFunc(){ std::cout &lt;&lt; &quot;Hello World&quot; &lt;&lt; std::endl;} 项目中的cmake内容 12PROJECT(HELLO)ADD_SUBDIRECTORY(lib bin) lib中CMakeLists.txt中的内容 12SET(LIBHELLO_SRC hello.cpp)ADD_LIBRARY(hello SHARED ${LIBHELLO_SRC}) 8.1.1 ADD_LIBRARYADD_LIBRARY(hello SHARED ${LIBHELLO_SRC}) hello：就是正常的库名，生成的名字前面会加上lib，最终产生的文件是libhello.so SHARED，动态库 STATIC，静态库 ${LIBHELLO_SRC} ：源文件 8.2 同时构建静态和动态库1234567// 如果用这种方式，只会构建一个动态库，不会构建出静态库，虽然静态库的后缀是.aADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})ADD_LIBRARY(hello STATIC ${LIBHELLO_SRC})// 修改静态库的名字，这样是可以的，但是我们往往希望他们的名字是相同的，只是后缀不同而已ADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})ADD_LIBRARY(hello_static STATIC ${LIBHELLO_SRC}) 8.2.1 SET_TARGET_PROPERTIES这条指令可以用来设置输出的名称，对于动态库，还可以用来指定动态库版本和 API 版本 同时构建静态和动态库 123456789101112SET(LIBHELLO_SRC hello.cpp)ADD_LIBRARY(hello_static STATIC ${LIBHELLO_SRC})//对hello_static的重名为helloSET_TARGET_PROPERTIES(hello_static PROPERTIES OUTPUT_NAME &quot;hello&quot;)//cmake 在构建一个新的target 时，会尝试清理掉其他使用这个名字的库，因为，在构建 libhello.so 时， 就会清理掉 libhello.aSET_TARGET_PROPERTIES(hello_static PROPERTIES CLEAN_DIRECT_OUTPUT 1)ADD_LIBRARY(hello SHARED ${LIBHELLO_SRC})SET_TARGET_PROPERTIES(hello PROPERTIES OUTPUT_NAME &quot;hello&quot;)SET_TARGET_PROPERTIES(hello PROPERTIES CLEAN_DIRECT_OUTPUT 1) CLEAN_DIRECT_OUTPUT新版本已经不需要了，直接重命名即可 8.3 动态库的版本号一般动态库都有一个版本号的关联 123libhello.so.1.2.3libhello.so -&gt;libhello.so.1libhello.so.1-&gt;libhello.so.1.2 CMakeLists.txt 插入如下 SET_TARGET_PROPERTIES(hello PROPERTIES VERSION 1.2 SOVERSION 1) VERSION 指代动态库版本（一般来说格式为：主版本号.次版本号.发布版本号），SOVERSION 指代主版本号。 8.4 安装共享库和头文件本例中我们将 hello 的共享库安装到&lt;prefix&gt;/lib目录， 将 hello.h 安装到&lt;prefix&gt;/include/hello 目录 123456//文件放到该目录下INSTALL(FILES hello.h DESTINATION include/hello)//二进制，静态库，动态库安装都用TARGETS//ARCHIVE 特指静态库，LIBRARY 特指动态库，RUNTIME 特指可执行目标二进制。INSTALL(TARGETS hello hello_static LIBRARY DESTINATION lib ARCHIVE DESTINATION lib) 注意： 安装的时候，指定一下路径，放到系统下 cmake -DCMAKE_INSTALL_PREFIX=/usr .. 8.5 解决：make后头文件找不到的问题PS：include &lt;hello/hello.h&gt; 这样include是可以，这么做的话，就没啥好讲的了 关键字：INCLUDE_DIRECTORIES 这条指令可以用来向工程添加多个特定的头文件搜索路径，路径之间用空格分割 在CMakeLists.txt中加入头文件搜索路径 INCLUDE_DIRECTORIES(/usr/include/hello) 8.6 解决：找到引用的函数问题报错信息：undefined reference to `HelloFunc()’ 方法一： 关键字：LINK_DIRECTORIES 添加非标准的共享库搜索路径 指定第三方库所在路径，LINK_DIRECTORIES(/home/myproject/libs) 方法二： 关键字：TARGET_LINK_LIBRARIES 添加需要链接的共享库 TARGET_LINK_LIBRARIES的时候，只需要给出动态链接库的名字就行了。 在CMakeLists.txt中插入链接共享库，主要要插在executable的后面 链接静态库 TARGET_LINK_LIBRARIES(main libhello.a) 8.7 特殊的环境变量 CMAKE_INCLUDE_PATH 和 CMAKE_LIBRARY_PATH注意：这两个是环境变量而不是 cmake 变量，可以在linux的bash中进行设置 我们上面例子中使用了绝对路径INCLUDE_DIRECTORIES(/usr/include/hello)来指明include路径的位置 我们还可以使用另外一种方式，使用环境变量export CMAKE_INCLUDE_PATH=/usr/include/hello 补充：生产debug版本的方法：cmake .. -DCMAKE_BUILD_TYPE=debug 学习自：从零开始详细介绍CMake_哔哩哔哩_bilibili","link":"/2023/04/24/CMake%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"gdb","slug":"gdb","link":"/tags/gdb/"},{"name":"C++ Tools","slug":"C-Tools","link":"/tags/C-Tools/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"事务","slug":"事务","link":"/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"排序","slug":"排序","link":"/tags/%E6%8E%92%E5%BA%8F/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"计算机网络","slug":"计算机网络","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"https","slug":"https","link":"/tags/https/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"多线程","slug":"多线程","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"栈","slug":"栈","link":"/tags/%E6%A0%88/"},{"name":"队列","slug":"队列","link":"/tags/%E9%98%9F%E5%88%97/"},{"name":"锁","slug":"锁","link":"/tags/%E9%94%81/"},{"name":"原子操作","slug":"原子操作","link":"/tags/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"name":"网络库","slug":"网络库","link":"/tags/%E7%BD%91%E7%BB%9C%E5%BA%93/"},{"name":"服务器","slug":"服务器","link":"/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"CMake","slug":"CMake","link":"/tags/CMake/"}],"categories":[{"name":"C++ Tools","slug":"C-Tools","link":"/categories/C-Tools/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"杂项","slug":"杂项","link":"/categories/%E6%9D%82%E9%A1%B9/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"计算机网络","slug":"计算机网络","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"C++","slug":"C","link":"/categories/C/"},{"name":"并发编程","slug":"并发编程","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"服务器","slug":"服务器","link":"/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}],"pages":[{"title":"categories","text":"","link":"/categories/index.html"}]}